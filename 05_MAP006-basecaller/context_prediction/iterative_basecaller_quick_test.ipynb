{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "from collections import OrderedDict\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from itertools import product as iterproduct, chain\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from nbwrapper import getargs\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/alignment_validation.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/alignment_lib.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/analysis_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "NMERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.events.template.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.called\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/LomanLab_MAP-006/ecoli_mg1655.fa\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1.model.pickle\",\n",
    "    \"corr_model\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/context_prediction/models/model-test2.pickle\",\n",
    "    \"ncores\": 62,\n",
    "    \"nmers\": NMERS,\n",
    "    \"multivariate\": False\n",
    "}\n",
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/wouter_lambda006_100.events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.called\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1.model.pickle\",\n",
    "#     \"corr_model\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/context_prediction/models/model-test2.pickle\",\n",
    "#     \"ncores\": 62,\n",
    "#     \"nmers\": NMERS,\n",
    "#     \"multivariate\": False\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMERS = int(args[\"nmers\"])\n",
    "NSTATES = 4**NMERS\n",
    "MULTIVARIATE = bool(int(args[\"multivariate\"]))\n",
    "args[\"ncores\"] = int(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = HMM_PARAMS[\"/opt/chimaera/model/r7.3_e6_70bps_6mer/template_median68pA.model\"]\n",
    "ALL_KMERS = [\"\".join(x) for x in iterproduct(\"ACGT\", repeat=NMERS)]\n",
    "assert HMM_PARAMS[\"kmer\"].tolist() == ALL_KMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat1(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 1/4. if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)] else 0.\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat0(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (9/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1 or move=2\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                \"\"\"move=2\"\"\"\n",
    "                p = (2/50.) * (1/16.)\n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (47/50.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/50.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mk_transmat = mk_transmat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_model_simple(): \n",
    "    \"\"\" simple model, only taking the means into account. \"\"\"\n",
    "    A = mk_transmat(NMERS)\n",
    "    B = HMM_PARAMS[[\"level_mean\", \"level_stdv\"]].values.tolist() #mu, std of each state\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = ghmm.Float()  # emission domain of this model\n",
    "def mk_model():\n",
    "    if MULTIVARIATE: \n",
    "        return mk_model_multivariate()\n",
    "    else: \n",
    "        return mk_model_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianEmissionHMM(N=4096)\n",
      "  state 0 (initial=0.00, mu=62.78, sigma=0.84)\n",
      "    Transitions: ->0 (0.00), ->1 (0.00), ->2 (0.00), ->3 (0.00), ->4 (0.00), ->5 (0.00), ->6 (0.00), ->7 (0.00), ->8 (0.00), ->9 (0.00), ->10 (0.00), ->11 (0.00), ->12 (0.00), ->13 (0.00), ->14 (0.00), ->15 (0.00)\n",
      "  state 1 (initial=0.00, mu=58.02, sigma=0.66)\n",
      "    Transitions: ->1 (0.02), ->4 (0.23), ->5 (0.23), ->6 (0.23), ->7 (0.23), ->16 (0.00), ->17 (0.00), ->18 (0.00), ->19 (0.00), ->20 (0.00), ->21 (0.00), ->22 (0.00), ->23 (0.00), ->24 (0.00), ->25 (0.00), ->26 (0.00), ->27 (0.00), ->28 (0.00), ->29 (0.00), ->30 (0.00), ->31 (0.00)\n",
      "\n",
      "  ...\n",
      "\n",
      "  state 4094 (initial=0.00, mu=45.36, sigma=0.64)\n",
      "    Transitions: ->4064 (0.00), ->4065 (0.00), ->4066 (0.00), ->4067 (0.00), ->4068 (0.00), ->4069 (0.00), ->4070 (0.00), ->4071 (0.00), ->4072 (0.00), ->4073 (0.00), ->4074 (0.00), ->4075 (0.00), ->4076 (0.00), ->4077 (0.00), ->4078 (0.00), ->4079 (0.00), ->4088 (0.23), ->4089 (0.23), ->4090 (0.23), ->4091 (0.23), ->4094 (0.02)\n",
      "  state 4095 (initial=0.00, mu=43.74, sigma=0.95)\n",
      "    Transitions: ->4080 (0.00), ->4081 (0.00), ->4082 (0.00), ->4083 (0.00), ->4084 (0.00), ->4085 (0.00), ->4086 (0.00), ->4087 (0.00), ->4088 (0.00), ->4089 (0.00), ->4090 (0.00), ->4091 (0.00), ->4092 (0.00), ->4093 (0.00), ->4094 (0.00), ->4095 (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = mk_model()\n",
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    kmers = [ALL_KMERS[x] for x in states]\n",
    "    seq = [kmer[0] for kmer in kmers] + [kmers[-1][1:]]\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(events):\n",
    "    \"\"\"mixed is a set of tuples (event_mean, event_stdv)\"\"\"\n",
    "    emissions = [x[0] for x in events]\n",
    "    seq = ghmm.EmissionSequence(F, emissions)\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = model.sampleSingle(10)\n",
    "s = [x for x in s]\n",
    "seq = zip([s[i] for i in range(0, len(s), 2)], [s[i] for i in range(1, len(s), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAGTGGCGCC'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ghmm.GaussianEmissionHMM at 0x7f2f00435210>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multistep-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "import joblib\n",
    "import mltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_model = joblib.load(args[\"corr_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OFFSET = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_col(features, col): \n",
    "    col_data = [f[col] for f in features]\n",
    "    col_data = mltools.normalize(col_data)\n",
    "    for i, f in enumerate(features): \n",
    "        f[col] = col_data[i]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_events(events, seq): \n",
    "    corr_range = (OFFSET, len(seq)-OFFSET-NMERS)\n",
    "#     print (\">> started feature generation\")\n",
    "    features = []\n",
    "    for i in range(*corr_range):\n",
    "        event = events[i]\n",
    "        feat = []\n",
    "        feat.append(event[0])\n",
    "        feat.append(event[1])\n",
    "        feat.extend(mltools.seq2binvec(seq[i-OFFSET:i+NMERS+OFFSET]))\n",
    "        features.append(feat)\n",
    "\n",
    "    features = normalize_col(features, 0)\n",
    "    features = normalize_col(features, 1)\n",
    "    \n",
    "    #print([x for x in enumerate(features[0])])\n",
    "        \n",
    "#     print (\">> started correction prediction\")\n",
    "    correction = corr_model.predict(features)\n",
    "    for i, j  in enumerate(range(*corr_range)):\n",
    "        mean, stdv = events[j]\n",
    "        tmp_mean = mean - .5 * correction[i]\n",
    "        ratio = tmp_mean/mean\n",
    "        tmp_stdv = ratio * stdv\n",
    "        events[j] = tmp_mean, tmp_stdv\n",
    "#     print (\">> correction applied\")\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_iterative(events, n_steps=3): \n",
    "    for _ in range(n_steps):\n",
    "#         print (\">> predict {0}\".format(_))\n",
    "        seq = predict(events)\n",
    "        if _ < n_steps-1: \n",
    "#             print (\">> correct {0}\".format(_))\n",
    "#             print(seq)\n",
    "#             print(means)\n",
    "            events = correct_events(events, seq)\n",
    "#             print(means)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_obj = correct_read(file_data[7], col=\"mean\")\n",
    "events = [(x[\"mean\"], x[\"stdv\"]) for x in file_obj[\"events\"].to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = predict(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CTTCTTGTTCAGTTTCTGAGCT'"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[18:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(55.60145482006586, 0.6603919956543661),\n",
       " (59.63927379425131, 2.321354572072122),\n",
       " (50.03479198061651, 0.48440114874166157),\n",
       " (48.50134036335742, 0.562943769826082),\n",
       " (41.90360182508564, 1.2487938620804517),\n",
       " (46.840335259801854, 0.9982156075538023),\n",
       " (59.13531558945736, 0.8090309460540313),\n",
       " (62.69417833392122, 1.7257578113042558),\n",
       " (49.48192750307938, 0.8809297388753783),\n",
       " (44.32932399549752, 0.7315835445520823),\n",
       " (43.20622155658872, 0.5149720773474338),\n",
       " (45.87098708017269, 0.7046783476310581)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[18:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_range = (OFFSET, len(seq)-OFFSET-NMERS)\n",
    "#     print (\">> started feature generation\")\n",
    "features = []\n",
    "for i in range(*corr_range):\n",
    "    event = events[i]\n",
    "    feat = []\n",
    "    feat.append(event[0])\n",
    "    feat.append(event[1])\n",
    "    feat.extend(mltools.seq2binvec(seq[i-OFFSET:i+NMERS+OFFSET]))\n",
    "    features.append(feat)\n",
    "\n",
    "features = normalize_col(features, 0)\n",
    "features = normalize_col(features, 1)\n",
    "\n",
    "#print([x for x in enumerate(features[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.3020380852778277),\n",
       " (1, 0.06079100131230351),\n",
       " (2, 0),\n",
       " (3, 1),\n",
       " (4, 0),\n",
       " (5, 0),\n",
       " (6, 1),\n",
       " (7, 0),\n",
       " (8, 0),\n",
       " (9, 0),\n",
       " (10, 0),\n",
       " (11, 0),\n",
       " (12, 1),\n",
       " (13, 0),\n",
       " (14, 0),\n",
       " (15, 0),\n",
       " (16, 0),\n",
       " (17, 1),\n",
       " (18, 0),\n",
       " (19, 0),\n",
       " (20, 0),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 0),\n",
       " (24, 0),\n",
       " (25, 0),\n",
       " (26, 0),\n",
       " (27, 0),\n",
       " (28, 0),\n",
       " (29, 1),\n",
       " (30, 0),\n",
       " (31, 0),\n",
       " (32, 1),\n",
       " (33, 0),\n",
       " (34, 0),\n",
       " (35, 0),\n",
       " (36, 0),\n",
       " (37, 1),\n",
       " (38, 0),\n",
       " (39, 1),\n",
       " (40, 0),\n",
       " (41, 0),\n",
       " (42, 0),\n",
       " (43, 0),\n",
       " (44, 0),\n",
       " (45, 1),\n",
       " (46, 0),\n",
       " (47, 0),\n",
       " (48, 1),\n",
       " (49, 0),\n",
       " (50, 0),\n",
       " (51, 0),\n",
       " (52, 0),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 0),\n",
       " (56, 0),\n",
       " (57, 0),\n",
       " (58, 0),\n",
       " (59, 0),\n",
       " (60, 1),\n",
       " (61, 0),\n",
       " (62, 0),\n",
       " (63, 0),\n",
       " (64, 0),\n",
       " (65, 1),\n",
       " (66, 1),\n",
       " (67, 0),\n",
       " (68, 0),\n",
       " (69, 0),\n",
       " (70, 1),\n",
       " (71, 0),\n",
       " (72, 0),\n",
       " (73, 0),\n",
       " (74, 0),\n",
       " (75, 1),\n",
       " (76, 0),\n",
       " (77, 0),\n",
       " (78, 0),\n",
       " (79, 0),\n",
       " (80, 0),\n",
       " (81, 1),\n",
       " (82, 0),\n",
       " (83, 0),\n",
       " (84, 0),\n",
       " (85, 1),\n",
       " (86, 0),\n",
       " (87, 1),\n",
       " (88, 0),\n",
       " (89, 0),\n",
       " (90, 0),\n",
       " (91, 0),\n",
       " (92, 0),\n",
       " (93, 1),\n",
       " (94, 0),\n",
       " (95, 0),\n",
       " (96, 0),\n",
       " (97, 1),\n",
       " (98, 0),\n",
       " (99, 0),\n",
       " (100, 1),\n",
       " (101, 0),\n",
       " (102, 0),\n",
       " (103, 0),\n",
       " (104, 0),\n",
       " (105, 1),\n",
       " (106, 0),\n",
       " (107, 0),\n",
       " (108, 0),\n",
       " (109, 1),\n",
       " (110, 0),\n",
       " (111, 1),\n",
       " (112, 0),\n",
       " (113, 0),\n",
       " (114, 1),\n",
       " (115, 0),\n",
       " (116, 0),\n",
       " (117, 0),\n",
       " (118, 0),\n",
       " (119, 0),\n",
       " (120, 1),\n",
       " (121, 0),\n",
       " (122, 0),\n",
       " (123, 0),\n",
       " (124, 0),\n",
       " (125, 1),\n",
       " (126, 0),\n",
       " (127, 0),\n",
       " (128, 0),\n",
       " (129, 1),\n",
       " (130, 0),\n",
       " (131, 0),\n",
       " (132, 0),\n",
       " (133, 1),\n",
       " (134, 0),\n",
       " (135, 1),\n",
       " (136, 0),\n",
       " (137, 0),\n",
       " (138, 0),\n",
       " (139, 0),\n",
       " (140, 0),\n",
       " (141, 1),\n",
       " (142, 0),\n",
       " (143, 0),\n",
       " (144, 1),\n",
       " (145, 0),\n",
       " (146, 1),\n",
       " (147, 0),\n",
       " (148, 0),\n",
       " (149, 0),\n",
       " (150, 0),\n",
       " (151, 0),\n",
       " (152, 1),\n",
       " (153, 0),\n",
       " (154, 0),\n",
       " (155, 1),\n",
       " (156, 0),\n",
       " (157, 0),\n",
       " (158, 0),\n",
       " (159, 0),\n",
       " (160, 0),\n",
       " (161, 1),\n",
       " (162, 1),\n",
       " (163, 0),\n",
       " (164, 0),\n",
       " (165, 0),\n",
       " (166, 1),\n",
       " (167, 0),\n",
       " (168, 0),\n",
       " (169, 0),\n",
       " (170, 0),\n",
       " (171, 1),\n",
       " (172, 0),\n",
       " (173, 0),\n",
       " (174, 0),\n",
       " (175, 0),\n",
       " (176, 1),\n",
       " (177, 0),\n",
       " (178, 1),\n",
       " (179, 0),\n",
       " (180, 0),\n",
       " (181, 0),\n",
       " (182, 1),\n",
       " (183, 0),\n",
       " (184, 0),\n",
       " (185, 0)]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in enumerate(features[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     print (\">> started correction prediction\")\n",
    "correction = corr_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.7993523 ,  0.37097458,  0.2274876 , -0.63482867,  0.36194889,\n",
       "        0.74804053,  1.0275012 ,  0.15076036, -0.02243579, -0.12817443])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50.03479198061651, 0.48440114874166157),\n",
       " (48.50134036335742, 0.562943769826082),\n",
       " (41.90360182508564, 1.2487938620804517),\n",
       " (46.840335259801854, 0.9982156075538023),\n",
       " (59.13531558945736, 0.8090309460540313),\n",
       " (62.69417833392122, 1.7257578113042558),\n",
       " (49.48192750307938, 0.8809297388753783),\n",
       " (44.32932399549752, 0.7315835445520823),\n",
       " (43.20622155658872, 0.5149720773474338),\n",
       " (45.87098708017269, 0.7046783476310581)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[OFFSET:OFFSET+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j  in enumerate(range(*corr_range)):\n",
    "    mean, stdv = events[j]\n",
    "    tmp_mean = mean - .5 * correction[i]\n",
    "    ratio = tmp_mean/mean\n",
    "    tmp_stdv = ratio * stdv\n",
    "    events[j] = tmp_mean, tmp_stdv\n",
    "#     print (\">> correction applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(49.635115830321332, 0.48053176948247267),\n",
       " (48.315853071308801, 0.56079086199593942),\n",
       " (41.78985802401013, 1.2454041162245775),\n",
       " (47.157749594072861, 1.004980032717995),\n",
       " (58.954341142318526, 0.80655503252045335),\n",
       " (62.320158069883199, 1.7154623036605985),\n",
       " (48.968176904224258, 0.87178340598710613),\n",
       " (44.253943814971343, 0.73033951701708277),\n",
       " (43.217439452614848, 0.51510578270309593),\n",
       " (45.935074292751452, 0.70566286690868674)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[OFFSET:OFFSET+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>gi|556503834|ref|NC_000913.3| Escherichia coli str. K-12 substr. MG1655, complete genome']\n",
      "AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGCTTCTGAACTGGTTACCTGCCGTGAGTAAAT\n"
     ]
    }
   ],
   "source": [
    "ref = load_ref(args[\"ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(file_obj):\n",
    "    file_obj = correct_read(file_obj, col=\"mean\")\n",
    "    events = [(x[\"mean\"], x[\"stdv\"]) for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    called_seq = predict_iterative(events)\n",
    "    return (file_obj[\"channel\"], file_obj[\"file_id\"], called_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"\"\" train with baum-welch \"\"\"\n",
    "# for i, file_obj in enumerate(file_data): \n",
    "#     sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "#     train_read(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#basecall_read(file_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction: \")\n",
    "results = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(basecall_read, file_data), 1):\n",
    "        results.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = [\"metrichor\", \"called\", \"random\"]\n",
    "fasta_files = {t: \"{0}.{1}.fa\".format(args[\"out_basename\"], t) for t in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## metrichor fasta\n",
    "with open(fasta_files[\"metrichor\"], 'w') as f: \n",
    "    for file_obj in file_data: \n",
    "        f.write(\">ch{0}_file{1}_metrichor\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "        f.write(file_obj[\"fastq\"].split(\"\\n\")[1] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## called fasta/random fasta\n",
    "with open(fasta_files[\"called\"], 'w') as f: \n",
    "    with open(fasta_files[\"random\"], 'w') as fr:\n",
    "        for channel, file_id, seq in results: \n",
    "            f.write(\">ch{0}_file{1}_called\".format(channel, file_id)+ \"\\n\")\n",
    "            fr.write(\">ch{0}_file{1}_random\".format(channel, file_id)+ \"\\n\")\n",
    "            f.write(seq + \"\\n\")\n",
    "            fr.write(\"\".join([random.choice(\"ACGT\") for _ in range(len(seq))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in types: \n",
    "    sam_file = \"{0}.{1}.sam\".format(args[\"out_basename\"], t)\n",
    "    graphmap(args[\"ref\"], fasta_files[t], sam_file, args[\"ncores\"])\n",
    "    prepare_sam(\"{0}.{1}\".format(args[\"out_basename\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_stat(t):\n",
    "    samfile = \"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t)\n",
    "    sst = samstats(samfile, ref, ncores=args[\"ncores\"])\n",
    "    return pandas.DataFrame(sst.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = map(mk_stat, types)\n",
    "print(types)\n",
    "side_by_side(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for t, df in zip(types, stats):\n",
    "#     with open(\"{0}.stats.{1}.html\".format(args[\"out_basename\"], t), 'w') as f:\n",
    "#         f.write(df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def score_consensus(t):\n",
    "#     consensus = mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t), ref_file)\n",
    "#     return(consensus)\n",
    "#     consensus = consensus.split(\"\\n\")[1].to_upper()\n",
    "#     score = needle(ref, consensus)\n",
    "#     return (consensus, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p = Pool(args[\"ncores\"])\n",
    "# try:\n",
    "#     consensus = p.map(score_consensus, types)\n",
    "#     p.close()\n",
    "# except KeyboardInterrupt:\n",
    "#     p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], \"metrichor\"), ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH einser ipython2",
   "language": "",
   "name": "rik_ssh_einser_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
