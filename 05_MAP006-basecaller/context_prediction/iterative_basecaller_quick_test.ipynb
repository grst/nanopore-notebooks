{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "from collections import OrderedDict\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from itertools import product as iterproduct, chain\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "from nbwrapper import getargs\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/alignment_validation.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/alignment_lib.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/lib/analysis_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "NMERS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.called\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/LomanLab_MAP-006/ecoli_mg1655.fa\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1.model.pickle\",\n",
    "#     \"corr_model\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/context_prediction/model-test.pickle\",\n",
    "#     \"ncores\": 62,\n",
    "#     \"nmers\": NMERS,\n",
    "#     \"multivariate\": False\n",
    "# }\n",
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/wouter_lambda006_100.events.template.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.called\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1.model.pickle\",\n",
    "    \"corr_model\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/context_prediction/model-test2.pickle\",\n",
    "    \"ncores\": 62,\n",
    "    \"nmers\": NMERS,\n",
    "    \"multivariate\": False\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "NMERS = int(args[\"nmers\"])\n",
    "NSTATES = 4**NMERS\n",
    "MULTIVARIATE = bool(int(args[\"multivariate\"]))\n",
    "args[\"ncores\"] = int(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = HMM_PARAMS[\"/opt/chimaera/model/r7.3_e6_70bps_6mer/template_median68pA.model\"]\n",
    "ALL_KMERS = [\"\".join(x) for x in iterproduct(\"ACGT\", repeat=NMERS)]\n",
    "assert HMM_PARAMS[\"kmer\"].tolist() == ALL_KMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat1(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 1/4. if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)] else 0.\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat0(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (9/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1 or move=2\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                \"\"\"move=2\"\"\"\n",
    "                p = (2/50.) * (1/16.)\n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (47/50.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/50.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mk_transmat = mk_transmat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_model_simple(): \n",
    "    \"\"\" simple model, only taking the means into account. \"\"\"\n",
    "    A = mk_transmat(NMERS)\n",
    "    B = HMM_PARAMS[[\"level_mean\", \"level_stdv\"]].values.tolist() #mu, std of each state\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "F = ghmm.Float()  # emission domain of this model\n",
    "def mk_model():\n",
    "    if MULTIVARIATE: \n",
    "        return mk_model_multivariate()\n",
    "    else: \n",
    "        return mk_model_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianEmissionHMM(N=4096)\n",
      "  state 0 (initial=0.00, mu=62.78, sigma=0.84)\n",
      "    Transitions: ->0 (0.00), ->1 (0.00), ->2 (0.00), ->3 (0.00), ->4 (0.00), ->5 (0.00), ->6 (0.00), ->7 (0.00), ->8 (0.00), ->9 (0.00), ->10 (0.00), ->11 (0.00), ->12 (0.00), ->13 (0.00), ->14 (0.00), ->15 (0.00)\n",
      "  state 1 (initial=0.00, mu=58.02, sigma=0.66)\n",
      "    Transitions: ->1 (0.02), ->4 (0.23), ->5 (0.23), ->6 (0.23), ->7 (0.23), ->16 (0.00), ->17 (0.00), ->18 (0.00), ->19 (0.00), ->20 (0.00), ->21 (0.00), ->22 (0.00), ->23 (0.00), ->24 (0.00), ->25 (0.00), ->26 (0.00), ->27 (0.00), ->28 (0.00), ->29 (0.00), ->30 (0.00), ->31 (0.00)\n",
      "\n",
      "  ...\n",
      "\n",
      "  state 4094 (initial=0.00, mu=45.36, sigma=0.64)\n",
      "    Transitions: ->4064 (0.00), ->4065 (0.00), ->4066 (0.00), ->4067 (0.00), ->4068 (0.00), ->4069 (0.00), ->4070 (0.00), ->4071 (0.00), ->4072 (0.00), ->4073 (0.00), ->4074 (0.00), ->4075 (0.00), ->4076 (0.00), ->4077 (0.00), ->4078 (0.00), ->4079 (0.00), ->4088 (0.23), ->4089 (0.23), ->4090 (0.23), ->4091 (0.23), ->4094 (0.02)\n",
      "  state 4095 (initial=0.00, mu=43.74, sigma=0.95)\n",
      "    Transitions: ->4080 (0.00), ->4081 (0.00), ->4082 (0.00), ->4083 (0.00), ->4084 (0.00), ->4085 (0.00), ->4086 (0.00), ->4087 (0.00), ->4088 (0.00), ->4089 (0.00), ->4090 (0.00), ->4091 (0.00), ->4092 (0.00), ->4093 (0.00), ->4094 (0.00), ->4095 (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = mk_model()\n",
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    kmers = [ALL_KMERS[x] for x in states]\n",
    "    seq = [kmer[0] for kmer in kmers] + [kmers[-1][1:]]\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(events):\n",
    "    \"\"\"mixed is a set of tuples (event_mean, event_stdv)\"\"\"\n",
    "    emissions = [x[0] for x in events]\n",
    "    seq = ghmm.EmissionSequence(F, emissions)\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = model.sampleSingle(10)\n",
    "s = [x for x in s]\n",
    "seq = zip([s[i] for i in range(0, len(s), 2)], [s[i] for i in range(1, len(s), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAGTAGAATT'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ghmm.GaussianEmissionHMM at 0x7f2efad1d050>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multistep-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "import joblib\n",
    "import mltools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_model = joblib.load(args[\"corr_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "OFFSET = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_col(features, col): \n",
    "    col_data = [f[col] for f in features]\n",
    "    col_data = mltools.normalize(col_data)\n",
    "    for i, f in enumerate(features): \n",
    "        f[col] = col_data[i]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct_events(events, seq): \n",
    "    corr_range = (OFFSET, len(seq)-OFFSET-NMERS)\n",
    "#     print (\">> started feature generation\")\n",
    "    features = []\n",
    "    for i in range(*corr_range):\n",
    "        event = events[i]\n",
    "        feat = []\n",
    "        feat.append(event[0])\n",
    "        feat.append(event[1])\n",
    "        feat.extend(mltools.seq2binvec(seq[i-OFFSET:i+NMERS+OFFSET]))\n",
    "        features.append(feat)\n",
    "\n",
    "    features = normalize_col(features, 0)\n",
    "    features = normalize_col(features, 1)\n",
    "    \n",
    "    #print([x for x in enumerate(features[0])])\n",
    "        \n",
    "#     print (\">> started correction prediction\")\n",
    "    correction = corr_model.predict(features)\n",
    "    for i, j  in enumerate(range(*corr_range)):\n",
    "        mean, stdv = events[j]\n",
    "        tmp_mean = mean - .1 * correction[i]\n",
    "        ratio = tmp_mean/mean\n",
    "        tmp_stdv = ratio * stdv\n",
    "        events[j] = tmp_mean, tmp_stdv\n",
    "#     print (\">> correction applied\")\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_iterative(events, n_steps=3): \n",
    "    for _ in range(n_steps):\n",
    "#         print (\">> predict {0}\".format(_))\n",
    "        seq = predict(events)\n",
    "        if _ < n_steps-1: \n",
    "#             print (\">> correct {0}\".format(_))\n",
    "#             print(seq)\n",
    "#             print(means)\n",
    "            events = correct_events(events, seq)\n",
    "#             print(means)\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_obj = correct_read(file_data[7], col=\"mean\")\n",
    "events = [(x[\"mean\"], x[\"stdv\"]) for x in file_obj[\"events\"].to_dict(\"records\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq = predict(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TTTTTCTGAGTTTCTATGTTCT'"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq[18:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42.0114784371039, 1.4727646945616364),\n",
       " (55.9587437487013, 1.550074569098511),\n",
       " (53.15756088466786, 1.4043851028579888),\n",
       " (58.20333326574283, 1.288266778560844),\n",
       " (56.59134890130535, 1.2428741876687441),\n",
       " (59.67519172629616, 1.2614077552503005),\n",
       " (51.35883735412172, 1.8434463365497897),\n",
       " (47.01933849506197, 1.0261942757723495),\n",
       " (41.604257702418096, 1.5104981235551942),\n",
       " (52.01943797533074, 1.3689371700490918),\n",
       " (50.070775821028185, 1.2075285245719574),\n",
       " (52.7758805257471, 0.9941203401742386)]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[18:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_range = (OFFSET, len(seq)-OFFSET-NMERS)\n",
    "#     print (\">> started feature generation\")\n",
    "features = []\n",
    "for i in range(*corr_range):\n",
    "    event = events[i]\n",
    "    feat = []\n",
    "    feat.append(event[0])\n",
    "    feat.append(event[1])\n",
    "    feat.extend(mltools.seq2binvec(seq[i-OFFSET:i+NMERS+OFFSET]))\n",
    "    features.append(feat)\n",
    "\n",
    "features = normalize_col(features, 0)\n",
    "features = normalize_col(features, 1)\n",
    "\n",
    "#print([x for x in enumerate(features[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.35172653679318944),\n",
       " (1, 0.2532404434099545),\n",
       " (2, 1),\n",
       " (3, 0),\n",
       " (4, 0),\n",
       " (5, 0),\n",
       " (6, 0),\n",
       " (7, 1),\n",
       " (8, 0),\n",
       " (9, 0),\n",
       " (10, 0),\n",
       " (11, 1),\n",
       " (12, 0),\n",
       " (13, 0),\n",
       " (14, 0),\n",
       " (15, 0),\n",
       " (16, 1),\n",
       " (17, 0),\n",
       " (18, 0),\n",
       " (19, 0),\n",
       " (20, 0),\n",
       " (21, 1),\n",
       " (22, 0),\n",
       " (23, 0),\n",
       " (24, 0),\n",
       " (25, 1),\n",
       " (26, 0),\n",
       " (27, 0),\n",
       " (28, 1),\n",
       " (29, 0),\n",
       " (30, 0),\n",
       " (31, 0),\n",
       " (32, 0),\n",
       " (33, 1),\n",
       " (34, 0),\n",
       " (35, 0),\n",
       " (36, 0),\n",
       " (37, 1),\n",
       " (38, 0),\n",
       " (39, 0),\n",
       " (40, 0),\n",
       " (41, 1),\n",
       " (42, 1),\n",
       " (43, 0),\n",
       " (44, 0),\n",
       " (45, 0),\n",
       " (46, 0),\n",
       " (47, 0),\n",
       " (48, 1),\n",
       " (49, 0),\n",
       " (50, 0),\n",
       " (51, 0),\n",
       " (52, 0),\n",
       " (53, 1),\n",
       " (54, 0),\n",
       " (55, 1),\n",
       " (56, 0),\n",
       " (57, 0),\n",
       " (58, 0),\n",
       " (59, 0),\n",
       " (60, 0),\n",
       " (61, 1),\n",
       " (62, 0),\n",
       " (63, 1),\n",
       " (64, 0),\n",
       " (65, 0),\n",
       " (66, 0),\n",
       " (67, 0),\n",
       " (68, 0),\n",
       " (69, 1),\n",
       " (70, 0),\n",
       " (71, 0),\n",
       " (72, 0),\n",
       " (73, 1),\n",
       " (74, 0),\n",
       " (75, 0),\n",
       " (76, 0),\n",
       " (77, 1),\n",
       " (78, 0),\n",
       " (79, 0),\n",
       " (80, 0),\n",
       " (81, 1),\n",
       " (82, 0),\n",
       " (83, 0),\n",
       " (84, 0),\n",
       " (85, 1),\n",
       " (86, 0),\n",
       " (87, 0),\n",
       " (88, 0),\n",
       " (89, 1),\n",
       " (90, 0),\n",
       " (91, 0),\n",
       " (92, 0),\n",
       " (93, 1),\n",
       " (94, 0),\n",
       " (95, 1),\n",
       " (96, 0),\n",
       " (97, 0),\n",
       " (98, 0),\n",
       " (99, 0),\n",
       " (100, 0),\n",
       " (101, 1),\n",
       " (102, 0),\n",
       " (103, 0),\n",
       " (104, 1),\n",
       " (105, 0),\n",
       " (106, 1),\n",
       " (107, 0),\n",
       " (108, 0),\n",
       " (109, 0),\n",
       " (110, 0),\n",
       " (111, 0),\n",
       " (112, 1),\n",
       " (113, 0),\n",
       " (114, 0),\n",
       " (115, 0),\n",
       " (116, 0),\n",
       " (117, 1),\n",
       " (118, 0),\n",
       " (119, 0),\n",
       " (120, 0),\n",
       " (121, 1),\n",
       " (122, 0),\n",
       " (123, 0),\n",
       " (124, 0),\n",
       " (125, 1),\n",
       " (126, 0),\n",
       " (127, 1),\n",
       " (128, 0),\n",
       " (129, 0),\n",
       " (130, 0),\n",
       " (131, 0),\n",
       " (132, 0),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 0),\n",
       " (136, 0),\n",
       " (137, 0),\n",
       " (138, 0),\n",
       " (139, 0),\n",
       " (140, 0),\n",
       " (141, 1),\n",
       " (142, 0),\n",
       " (143, 0),\n",
       " (144, 1),\n",
       " (145, 0),\n",
       " (146, 0),\n",
       " (147, 0),\n",
       " (148, 0),\n",
       " (149, 1),\n",
       " (150, 0),\n",
       " (151, 0),\n",
       " (152, 0),\n",
       " (153, 1),\n",
       " (154, 0),\n",
       " (155, 1),\n",
       " (156, 0),\n",
       " (157, 0),\n",
       " (158, 0),\n",
       " (159, 0),\n",
       " (160, 0),\n",
       " (161, 1),\n",
       " (162, 0),\n",
       " (163, 1),\n",
       " (164, 0),\n",
       " (165, 0),\n",
       " (166, 0),\n",
       " (167, 0),\n",
       " (168, 0),\n",
       " (169, 1),\n",
       " (170, 1),\n",
       " (171, 0),\n",
       " (172, 0),\n",
       " (173, 0),\n",
       " (174, 0),\n",
       " (175, 0),\n",
       " (176, 0),\n",
       " (177, 1),\n",
       " (178, 0),\n",
       " (179, 1),\n",
       " (180, 0),\n",
       " (181, 0),\n",
       " (182, 0),\n",
       " (183, 0),\n",
       " (184, 0),\n",
       " (185, 1)]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in enumerate(features[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     print (\">> started correction prediction\")\n",
    "correction = corr_model.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OFFSET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.53169365,  1.38059966, -0.13873391, -0.56596379,  1.78664566,\n",
       "        0.48308305,  0.22211348,  0.87392437, -0.82151468, -0.39801699])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correction[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53.15756088466786, 1.4043851028579888),\n",
       " (58.20333326574283, 1.288266778560844),\n",
       " (56.59134890130535, 1.2428741876687441),\n",
       " (59.67519172629616, 1.2614077552503005),\n",
       " (51.35883735412172, 1.8434463365497897),\n",
       " (47.01933849506197, 1.0261942757723495),\n",
       " (41.604257702418096, 1.5104981235551942),\n",
       " (52.01943797533074, 1.3689371700490918),\n",
       " (50.070775821028185, 1.2075285245719574),\n",
       " (52.7758805257471, 0.9941203401742386)]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[OFFSET:OFFSET+10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i, j  in enumerate(range(*corr_range)):\n",
    "    mean, stdv = events[j]\n",
    "    tmp_mean = mean - .5 * correction[i]\n",
    "    ratio = tmp_mean/mean\n",
    "    tmp_stdv = ratio * stdv\n",
    "    events[j] = tmp_mean, tmp_stdv\n",
    "#     print (\">> correction applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(53.423407707286991, 1.4114085875912044),\n",
       " (57.513033435219526, 1.2729877509001934),\n",
       " (56.660715855520294, 1.2443976430827741),\n",
       " (59.95817361889921, 1.2673893959220572),\n",
       " (50.465514523041506, 1.8113818899004939),\n",
       " (46.777796969839486, 1.0209226463007721),\n",
       " (41.493200961783224, 1.5064660603097206),\n",
       " (51.582475788535191, 1.3574381265628082),\n",
       " (50.481533162356662, 1.2174345265900681),\n",
       " (52.97488902126711, 0.99786899185551936)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events[OFFSET:OFFSET+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>burn-in lambda_ref']\n",
      "GGGCGGCGACCTCGCGGGTTTTCGCTATTTATGAAAATTTTCCGGTTTAAGGCGTTTCCGTTCTTCTTCGTCATAACTTAATGTTTTTATTTAAAATACC\n"
     ]
    }
   ],
   "source": [
    "ref = load_ref(args[\"ref\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(file_obj):\n",
    "    file_obj = correct_read(file_obj, col=\"mean\")\n",
    "    events = [(x[\"mean\"], x[\"stdv\"]) for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    called_seq = predict_iterative(events)\n",
    "    return (file_obj[\"channel\"], file_obj[\"file_id\"], called_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \"\"\" train with baum-welch \"\"\"\n",
    "# for i, file_obj in enumerate(file_data): \n",
    "#     sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "#     train_read(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#basecall_read(file_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction: \")\n",
    "results = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(basecall_read, file_data), 1):\n",
    "        results.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = [\"metrichor\", \"called\", \"random\"]\n",
    "fasta_files = {t: \"{0}.{1}.fa\".format(args[\"out_basename\"], t) for t in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## metrichor fasta\n",
    "with open(fasta_files[\"metrichor\"], 'w') as f: \n",
    "    for file_obj in file_data: \n",
    "        f.write(\">ch{0}_file{1}_metrichor\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "        f.write(file_obj[\"fastq\"].split(\"\\n\")[1] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## called fasta/random fasta\n",
    "with open(fasta_files[\"called\"], 'w') as f: \n",
    "    with open(fasta_files[\"random\"], 'w') as fr:\n",
    "        for channel, file_id, seq in results: \n",
    "            f.write(\">ch{0}_file{1}_called\".format(channel, file_id)+ \"\\n\")\n",
    "            fr.write(\">ch{0}_file{1}_random\".format(channel, file_id)+ \"\\n\")\n",
    "            f.write(seq + \"\\n\")\n",
    "            fr.write(\"\".join([random.choice(\"ACGT\") for _ in range(len(seq))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in types: \n",
    "    sam_file = \"{0}.{1}.sam\".format(args[\"out_basename\"], t)\n",
    "    graphmap(args[\"ref\"], fasta_files[t], sam_file, args[\"ncores\"])\n",
    "    prepare_sam(\"{0}.{1}\".format(args[\"out_basename\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_stat(t):\n",
    "    samfile = \"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t)\n",
    "    sst = samstats(samfile, ref, ncores=args[\"ncores\"])\n",
    "    return pandas.DataFrame(sst.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = map(mk_stat, types)\n",
    "print(types)\n",
    "side_by_side(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for t, df in zip(types, stats):\n",
    "#     with open(\"{0}.stats.{1}.html\".format(args[\"out_basename\"], t), 'w') as f:\n",
    "#         f.write(df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def score_consensus(t):\n",
    "#     consensus = mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t), ref_file)\n",
    "#     return(consensus)\n",
    "#     consensus = consensus.split(\"\\n\")[1].to_upper()\n",
    "#     score = needle(ref, consensus)\n",
    "#     return (consensus, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# p = Pool(args[\"ncores\"])\n",
    "# try:\n",
    "#     consensus = p.map(score_consensus, types)\n",
    "#     p.close()\n",
    "# except KeyboardInterrupt:\n",
    "#     p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], \"metrichor\"), ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH einser ipython2",
   "language": "",
   "name": "rik_ssh_einser_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
