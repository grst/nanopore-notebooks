{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nbwrapper import getargs\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import marshal\n",
    "import h5py\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "import re\n",
    "import os.path\n",
    "import sys\n",
    "from itertools import repeat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/bin/anaconda3/lib/python3.4/site-packages/nbwrapper.py:31: RuntimeWarning: no arguments passed!\n",
      "  warnings.warn(\"no arguments passed!\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### for testing only\n",
    "# args = {\n",
    "#     \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/processed/\", ## path to processed f5-files\n",
    "#     \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events\", \n",
    "#     \"ncores\": 24,\n",
    "# }\n",
    "# args = {\n",
    "#     \"f5_path\": \"/storageNGS/ngs1/projects/other/NanoporeData/burnin_downloads/\", ## path to processed f5-files\n",
    "#     \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events\", \n",
    "#     \"ncores\": 60,\n",
    "# }\n",
    "# args = {\n",
    "#     \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/LomanLab_MAP-006/MAP006-1_100/\", ## path to processed f5-files\n",
    "#     \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_100.events\", \n",
    "#     \"ncores\": 60,\n",
    "#     \"nmers\": 6\n",
    "# }\n",
    "args = {\n",
    "    \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/wouter_de_coster_map-006_lambda/Lambda006_20151117/fast5/\", ## path to processed f5-files\n",
    "    \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/wouter_lambda006.events\", \n",
    "    \"ncores\": 60,\n",
    "    \"nmers\": 6,\n",
    "    \"new_file_format\": True\n",
    "}\n",
    "# args = {\n",
    "#     \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/LomanLab_MAP-006/MAP006-1_5000/\", ## path to processed f5-files\n",
    "#     \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1_5000.events\", \n",
    "#     \"ncores\": 80,\n",
    "#     \"nmers\": 6\n",
    "# }\n",
    "# args = {\n",
    "#     \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/PublicData/LomanLab_MAP-006/MAP006-1/\", ## path to processed f5-files\n",
    "#     \"output_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/05_MAP006-basecaller/loman006-1.events\", \n",
    "#     \"ncores\": 80,\n",
    "#     \"nmers\": 6\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.isdir(args[\"f5_path\"])\n",
    "args[\"ncores\"] = int(args[\"ncores\"])\n",
    "assert args[\"ncores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRATE = 5000\n",
    "NMERS = args[\"nmers\"]\n",
    "TYPES = [\"template\", \"complement\", \"2D\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2968\n"
     ]
    }
   ],
   "source": [
    "files = !find {args[\"f5_path\"]} | grep \"\\.fast5\"\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "files = sorted(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_and_channel(filename):\n",
    "    result = re.search(r'ch(\\d+)_file(\\d+)_', filename)\n",
    "    file_id = int(result.group(2))\n",
    "    channel_id = int(result.group(1))\n",
    "    return file_id, channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmer2move(prev_kmer, curr_kmer):\n",
    "    \"\"\"calculates the shift between two kmers. \n",
    "    If multiple shifts are possible (repeats), \n",
    "    the minimal possible shift is assumed.\"\"\"\n",
    "    if(prev_kmer is None): return 0 #first position \n",
    "    assert len(prev_kmer) == len(curr_kmer)\n",
    "    l = len(prev_kmer)\n",
    "    for i in range(0, l): \n",
    "        if prev_kmer[i:] == curr_kmer[:l-i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def get_models(f5):\n",
    "    log = f5['/Analyses/Basecall_2D_000/Log']\n",
    "    log = bytes(log[...]).decode(\"utf-8\").split(\"\\n\")\n",
    "    model = [x for x in log if x.find(\".model\") >= 0]\n",
    "    model = [re.search(r\"\\\"(.*)\\\"\", x).group(1) for x in model]\n",
    "    models = {}\n",
    "    for t in [\"template\", \"complement\"]:\n",
    "        try:\n",
    "            m_name = [x for x in model if x.find(t) >= 0][0]\n",
    "        except IndexError:\n",
    "            m_name = None\n",
    "        models[t] = m_name\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "if \"new_file_format\" in args and args[\"new_file_format\"]: \n",
    "    f5_event_path = '/Analyses/Basecall_1D_000/BaseCalled_{0}'\n",
    "else:\n",
    "    f5_event_path = '/Analyses/Basecall_2D_000/BaseCalled_{0}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_metrichor_file(file):\n",
    "    \"\"\"\n",
    "    reads every filename in files with poretools and \n",
    "    extracts events and metadata\n",
    "    \"\"\"  \n",
    "    \n",
    "    tmp_out = []\n",
    "    \n",
    "    def log(tmp_out):\n",
    "        pass\n",
    "#         print(\"\\n\".join(tmp_out) + \"\\n\")\n",
    "#         sys.stdout.flush()        \n",
    "        \n",
    "    file_id, ch_id = get_file_and_channel(file)\n",
    "    tmp_out.append(\"processing file {0} channel {1}\".format(\n",
    "        file_id, ch_id))\n",
    "\n",
    "    try:\n",
    "        f5 = h5py.File(file, 'r')\n",
    "    except OSError:\n",
    "        tmp_out.append(\"Unablable to open file\")\n",
    "        log(tmp_out)\n",
    "        return None\n",
    "    fastq = {}\n",
    "    for t in TYPES: \n",
    "        try: \n",
    "            fastq[t] = bytes(f5[(f5_event_path + '/Fastq').format(t)][...]).decode('utf-8')\n",
    "        except KeyError:\n",
    "            fastq[t] = None           \n",
    "           \n",
    "    def process_1d(t): \n",
    "        try:\n",
    "            raw_events = f5[(f5_event_path + '/Events').format(t)] \n",
    "        except KeyError:\n",
    "            return None\n",
    "        events = []\n",
    "        tmp_out.append(\"  >> processing {0} events\".format(t))\n",
    "        for raw_ev in raw_events: \n",
    "            ev = {}\n",
    "            ev[\"mean\"] = raw_ev[0]\n",
    "            ev[\"start\"] = round(float(raw_ev[1]) * SRATE)\n",
    "            ev[\"stdv\"] = raw_ev[2]\n",
    "            ev[\"end\"] = round((float(raw_ev[1]) + float(raw_ev[3])) * SRATE) - 1\n",
    "            ev[\"kmer\"] = bytes(raw_ev[4]).decode('utf-8')\n",
    "            ev[\"move\"] = int(raw_ev[6])\n",
    "            events.append(ev)\n",
    "        return events   \n",
    "        \n",
    "            \n",
    "    def process_2d(all_events):\n",
    "        \"\"\"generate 2d read from alignment and the 1d reads\"\"\"\n",
    "        try:\n",
    "            aln = f5['/Analyses/Basecall_2D_000/BaseCalled_2D/Alignment']   \n",
    "        except KeyError:\n",
    "            return None\n",
    "        tmp_out.append(\"  >> processing {0} events\".format(\"2D\"))\n",
    "        events = []\n",
    "        prev_kmer = None\n",
    "        for pos in aln:  \n",
    "            ids = {\"template\": pos[0], \"complement\": pos[1]}\n",
    "            kmer = pos[2]\n",
    "            move = kmer2move(prev_kmer, kmer)\n",
    "            prev_kmer = kmer\n",
    "            ev = {}\n",
    "            ev[\"move\"] = move\n",
    "            ev[\"kmer\"] = bytes(kmer).decode('utf-8')\n",
    "            for t, tmp_id in ids.items():  \n",
    "                for f in [\"mean\", \"start\", \"stdv\", \"end\"]:\n",
    "                    ev[\"{0}.{1}\".format(t, f)] = None if tmp_id < 0 else all_events[t][tmp_id][f]                    \n",
    "            events.append(ev)\n",
    "        return events\n",
    "\n",
    "    all_events = {t: process_1d(t) for t in [\"template\", \"complement\"]}\n",
    "    all_events[\"2D\"] = process_2d(all_events)\n",
    "    all_events = {t: pandas.DataFrame(events) for t, events in all_events.items()}\n",
    "  \n",
    "    models = get_models(f5)\n",
    "    median = {t: all_events[t][\"mean\"].median() for t in [\"template\", \"complement\"] if not all_events[t].empty}\n",
    "    #median = {t: np.median([x[\"mean\"] for x in all_events[t]]) for t in [\"template\", \"complement\"] if all_events[t] is not None}\n",
    "\n",
    "    \n",
    "    f_obj = {\n",
    "        \"channel\": ch_id,\n",
    "        \"file_id\": file_id, \n",
    "        \"events\": all_events,\n",
    "        \"models\": models,\n",
    "        \"median\": median, \n",
    "        \"fastq\": fastq\n",
    "    }\n",
    "    log(tmp_out)\n",
    "    return f_obj\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Analyses/Basecall_1D_000/BaseCalled_{0}'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files[0]\n",
    "f5_event_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make Events: \n",
      "done 3.706199%"
     ]
    }
   ],
   "source": [
    "print(\"Make Events: \")\n",
    "file_data = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(process_metrichor_file, files), 1):\n",
    "        file_data.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(files))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in TYPES:\n",
    "    tmp_file_data = []\n",
    "    for f_obj in file_data:\n",
    "        if f_obj[\"events\"][t] is not None and f_obj[\"fastq\"][t] is not None:\n",
    "            tmp_f_obj = {\n",
    "                \"models\": f_obj[\"models\"],\n",
    "                \"median\": f_obj[\"median\"],\n",
    "                \"channel\": f_obj[\"channel\"],\n",
    "                \"file_id\": f_obj[\"file_id\"],\n",
    "                \"events\": f_obj[\"events\"][t],\n",
    "                \"fastq\": f_obj[\"fastq\"][t]\n",
    "            }\n",
    "            tmp_file_data.append(tmp_f_obj)       \n",
    "    filename = \"{0}.{1}.pickle\".format(args[\"output_basename\"], t)\n",
    "    pickle.dump(tmp_file_data, open(filename, 'wb'), protocol=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "# for t in TYPES:\n",
    "#     tmp_file_data = []\n",
    "#     for f_obj in file_data:\n",
    "#         if f_obj[\"events\"][t] is not None and f_obj[\"fastq\"][t] is not None:\n",
    "#             tmp_f_obj = {\n",
    "#                 \"models\": f_obj[\"models\"],\n",
    "#                 \"median\": f_obj[\"median\"],\n",
    "#                 \"channel\": f_obj[\"channel\"],\n",
    "#                 \"file_id\": f_obj[\"file_id\"],\n",
    "#                 \"events\": f_obj[\"events\"][t],\n",
    "#                 \"fastq\": f_obj[\"fastq\"][t]\n",
    "#             }\n",
    "#             tmp_file_data.append([(k, v) for k, v in tmp_f_obj.items()])       \n",
    "#     filename = \"{0}.{1}.marshal\".format(args[\"output_basename\"], t)\n",
    "#     marshal.dump(tuple(tmp_file_data), open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH einser ipython",
   "language": "",
   "name": "rik_ssh_einser_ipython"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
