{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nbwrapper import getargs\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import h5py\n",
    "import pandas\n",
    "from pprint import pprint\n",
    "import re\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sturm/bin/anaconda3/lib/python3.4/site-packages/nbwrapper.py:28: RuntimeWarning: no arguments passed!\n",
      "  warnings.warn(\"no arguments passed!\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sturm/repos/uni/nanopore/own/notebooks/03_pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ### for testing only\n",
    "# args = {\n",
    "#     \"f5_path\": \"/home/ibis/gregor.sturm/nanopore/NanoporeData/burnin_downloads/\", ## path to processed f5-files\n",
    "#     \"output\": \"file_data_lambda.pickle\", \n",
    "#     \"ncores\": 4,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.isdir(args[\"f5_path\"])\n",
    "args[\"ncores\"] = int(args[\"ncores\"])\n",
    "assert args[\"ncores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SRATE = 5000\n",
    "NMERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6434\n"
     ]
    }
   ],
   "source": [
    "files = !find {args[\"f5_path\"]} | grep fast5\n",
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_file_and_channel(filename):\n",
    "    result = re.search(r'ch(\\d+)_file(\\d+)_', filename)\n",
    "    file_id = int(result.group(2))\n",
    "    channel_id = int(result.group(1))\n",
    "    return file_id, channel_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmer2move(prev_kmer, curr_kmer):\n",
    "    \"\"\"calculates the shift between two kmers. \n",
    "    If multiple shifts are possible (repeats), \n",
    "    the minimal possible shift is assumed.\"\"\"\n",
    "    if(prev_kmer is None): return 0 #first position \n",
    "    assert len(prev_kmer) == len(curr_kmer)\n",
    "    l = len(prev_kmer)\n",
    "    for i in range(0, l): \n",
    "        if prev_kmer[i:] == curr_kmer[:l-i]:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_metrichor_file(file):\n",
    "    \"\"\"\n",
    "    reads every filename in files with poretools and \n",
    "    extracts events and metadata\n",
    "    \"\"\"    \n",
    "\n",
    "    tmp_out = []\n",
    "    types = [\"template\", \"complement\", \"2D\"]\n",
    "    file_id, ch_id = get_file_and_channel(file)\n",
    "    tmp_out.append(\"processing file {0} channel {1}\".format(\n",
    "        file_id, ch_id))\n",
    "\n",
    "    f5 = h5py.File(file, 'r')\n",
    "    fastq = {}\n",
    "    for t in types: \n",
    "        try: \n",
    "            fastq[t] = bytes(f5['/Analyses/Basecall_2D_000/BaseCalled_{0}/Fastq'.format(t)][...]).decode('utf-8')\n",
    "        except KeyError:\n",
    "            fastq[t] = None\n",
    "\n",
    "    if(all([not x for x in fastq.values()])): \n",
    "        tmp_out.append(\"\\tempty file, skipped. \")\n",
    "        print(\"\\n\".join(tmp_out) + \"\\n\")\n",
    "        return None\n",
    "\n",
    "    events = {}\n",
    "    for t in [\"template\", \"complement\"]: \n",
    "        if fastq[t]:\n",
    "            events[t] = f5['/Analyses/Basecall_2D_000/BaseCalled_{0}/Events'.format(t)]\n",
    "\n",
    "    if fastq[\"2D\"]:\n",
    "        \"\"\"2d read\"\"\"\n",
    "        aln = f5['/Analyses/Basecall_2D_000/BaseCalled_2D/Alignment']   \n",
    "        events[\"2D\"] = []\n",
    "        prev_kmer = None\n",
    "        for pos in aln:  \n",
    "            ids = {}\n",
    "            ids[\"template\"], ids[\"complement\"], kmer = pos\n",
    "            move = kmer2move(prev_kmer, kmer)\n",
    "            prev_kmer = kmer\n",
    "            ev = {}\n",
    "            ev[\"move\"] = move\n",
    "            ev[\"kmer\"] = bytes(kmer).decode('utf-8')\n",
    "            for t, tmp_id in ids.items():  \n",
    "                tmp_event = None if tmp_id < 0 else events[t][tmp_id]\n",
    "                ev[t] = tmp_id\n",
    "                ev[\"{0}.mean\".format(t)] = None if tmp_event is None else tmp_event[0]\n",
    "                ev[\"{0}.start\".format(t)] = None if tmp_event is None else round(float(tmp_event[1]) * SRATE)\n",
    "                ev[\"{0}.stdv\".format(t)] = None if tmp_event is None else tmp_event[2]\n",
    "                ev[\"{0}.end\".format(t)] = None if tmp_event is None else (\n",
    "                            round((float(tmp_event[1]) + float(tmp_event[3])) * SRATE)-1)\n",
    "\n",
    "            events[\"2D\"].append(ev)\n",
    "\n",
    "    else: \n",
    "        \"\"\"1d read(s) only\"\"\"\n",
    "        ## not implemented\n",
    "        tmp_out.append(\"\\tno 2d reads, skipped.\")\n",
    "        print(\"\\n\".join(tmp_out) + \"\\n\")\n",
    "        return None\n",
    "\n",
    "\n",
    "    f_obj = {\n",
    "        \"channel\": ch_id,\n",
    "        \"file_id\": file_id, \n",
    "        \"events\": pandas.DataFrame(events[\"2D\"]),\n",
    "        \"fastq\": fastq[\"2D\"]\n",
    "    }\n",
    "    print(\"\\n\".join(tmp_out) + \"\\n\")\n",
    "    return f_obj\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file 12 channel 101\n",
      "\tno 2d reads, skipped.\n",
      "processing file 11 channel 101\n",
      "\tno 2d reads, skipped.\n",
      "processing file 14 channel 101\n",
      "\tno 2d reads, skipped.\n",
      "processing file 0 channel 101\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    file_data = p.map(process_metrichor_file, files)\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(file_data, open(args[\"output\"], 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
