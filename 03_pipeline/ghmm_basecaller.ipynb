{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMERS = 5\n",
    "NSTATES = 4**NMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_calling\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/mouse_ref.fa\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_hmm_params_{0}mer.pickle\".format(NMERS)\",\n",
    "#     \"ncores\": 4\n",
    "# }\n",
    "\n",
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events.template.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_calling\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "    \"ncores\": 62\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = sorted(zip(*[HMM_PARAMS[\"kmers\"], HMM_PARAMS[\"means\"], HMM_PARAMS[\"stdv\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 1/4. if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)] else 0.\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat0(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (9/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1 or move=2\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                \"\"\"move=2\"\"\"\n",
    "                p = (3/10.) * (1/16.)\n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (7/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (0/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# example code for a continuous HMM with gaussian emissions\n",
    "\n",
    "\n",
    "F = ghmm.Float()  # emission domain of this model\n",
    "\n",
    "A = mk_transmat(NMERS)\n",
    "B = [[x[1], x[2]] for x in HMM_PARAMS]   # parameters of emission distributions in pairs of (mu, sigma)\n",
    "pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "\n",
    "# generate model from parameters\n",
    "model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianEmissionHMM(N=64)\n",
      "  state 0 (initial=0.00, mu=67.75, sigma=3.49)\n",
      "    Transitions: ->0 (0.25)\n",
      "  state 1 (initial=0.00, mu=61.09, sigma=3.02)\n",
      "    Transitions: ->1 (0.25)\n",
      "\n",
      "  ...\n",
      "\n",
      "  state 62 (initial=0.00, mu=52.22, sigma=2.39)\n",
      "    Transitions: ->62 (0.25)\n",
      "  state 63 (initial=0.00, mu=47.64, sigma=2.26)\n",
      "    Transitions: ->63 (0.25)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    kmers = [all_kmers[x] for x in states]\n",
    "    seq = [kmer[NMERS/2] for kmer in kmers]\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(means):\n",
    "    seq = ghmm.EmissionSequence(F, means)\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'TTTTTTTTT'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([44.2, 44.3, 56, 58.2, 56.2, 58.1, 58.2, 60, 30.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>burn-in lambda_ref']\n",
      "GGGCGGCGACCTCGCGGGTTTTCGCTATTTATGAAAATTTTCCGGTTTAAGGCGTTTCCGTTCTTCTTCGTCATAACTTAATGTTTTTATTTAAAATACC\n"
     ]
    }
   ],
   "source": [
    "ref_file = args[\"ref\"]\n",
    "test = !cat {ref_file} | grep \">\"\n",
    "print(test)\n",
    "ref = !cat {ref_file} | grep -v \">\"\n",
    "ref = ref[0]\n",
    "print(ref[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastq_file = \"{0}.fastq\".format(args[\"out_basename\"])\n",
    "mk_fastq(fastq_file, file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index 09:52:07] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 09:52:07] Index already exists. Loading from file.\n",
      "[Index 09:52:07] Secondary index already exists. Loading from file.\n",
      "[Index 09:52:08] Index loaded in 0.46 sec.\n",
      "[Index 09:52:08] Memory consumption: [currentRSS = 516 MB, peakRSS = 15658 MB]\n",
      "\n",
      "[Run 09:52:08] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 09:52:08] Reference genome is assumed to be linear.\n",
      "[Run 09:52:08] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 09:52:08] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 09:52:08] Batch of 6123 reads (64 MiB) loaded in 0.49 sec. (38556840 bases)\n",
      "[ProcessReads 09:52:08] Memory consumption: [currentRSS = 582 MB, peakRSS = 15658 MB]\n",
      "[ProcessReads 09:52:08] Using 62 threads.\n",
      "[ProcessReads 09:53:05] [CPU time: 1965.67 sec, RSS: 603 MB] Read: 6123/6123 (100.00%) [m: 5709, u: 414]                                                           \n",
      "\n",
      "[ProcessReads 09:53:05] Memory consumption: [currentRSS = 602 MB, peakRSS = 15658 MB]\n",
      "\n",
      "[ProcessReads 09:53:05] All reads processed in 1965.72 sec (or 32.76 CPU min).\n"
     ]
    }
   ],
   "source": [
    "sam_file = \"{0}.sam\".format(args[\"out_basename\"])\n",
    "graphmap(ref_file, fastq_file, sam_file, args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bam_file = prepare_sam(args[\"out_basename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samfile = pysam.AlignmentFile(bam_file)\n",
    "reads  = [x for x in samfile.fetch()]\n",
    "len(reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(params):\n",
    "    read_name, ref_pos = params\n",
    "    file_id, channel_id = get_file_and_channel(read_name)\n",
    "    print(file_id, channel_id, read_name)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    file_obj = get_file(channel_id, file_id)\n",
    "      \n",
    "    events = [x[\"mean\"] for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    metrichor_seq = file_obj[\"fastq\"].split(\"\\n\")[1]\n",
    "    ref_seq = \"\".join([ref[x] for x in ref_pos])\n",
    "    called_seq = predict(events)\n",
    "    \n",
    "    stats = {\n",
    "        \"d_metrichor\": int(editdistance.eval(ref_seq, metrichor_seq)),\n",
    "        \"d_caller\": int(editdistance.eval(ref_seq, called_seq)), \n",
    "        \"length\": len(ref_seq),\n",
    "    }\n",
    "\n",
    "    return (read_name, called_seq, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 107, 'ch107_file16_read')\n",
      "(22, 283, 'ch283_file22_read')\n",
      "(2, 435, 'ch435_file2_read')\n",
      "(18, 87, 'ch87_file18_read')\n",
      "(5, 34, 'ch34_file5_read')\n",
      "(5, 211, 'ch211_file5_read')\n",
      "(22, 19, 'ch19_file22_read')\n",
      "(9, 385, 'ch385_file9_read')\n",
      "(4, 195, 'ch195_file4_read')\n",
      "(22, 219, 'ch219_file22_read')\n",
      "(10, 9, 'ch9_file10_read')\n",
      "(14, 413, 'ch413_file14_read')\n",
      "(11, 71, 'ch71_file11_read')\n",
      "(4, 377, 'ch377_file4_read')\n",
      "(9, 154, 'ch154_file9_read')\n",
      "(43, 450, 'ch450_file43_read')\n",
      "(5, 98, 'ch98_file5_read')\n",
      "(1, 391, 'ch391_file1_read')\n",
      "(0, 400, 'ch400_file0_read')\n",
      "(25, 23, 'ch23_file25_read')\n",
      "(1, 333, 'ch333_file1_read')\n",
      "(16, 236, 'ch236_file16_read')\n",
      "(11, 16, 'ch16_file11_read')\n",
      "(6, 458, 'ch458_file6_read')\n",
      "(19, 280, 'ch280_file19_read')\n",
      "(20, 500, 'ch500_file20_read')\n",
      "(5, 77, 'ch77_file5_read')\n",
      "(11, 493, 'ch493_file11_read')\n",
      "(35, 452, 'ch452_file35_read')\n",
      "(21, 96, 'ch96_file21_read')\n",
      "(25, 22, 'ch22_file25_read')\n",
      "(20, 216, 'ch216_file20_read')\n",
      "(5, 496, 'ch496_file5_read')\n",
      "(2, 308, 'ch308_file2_read')\n",
      "(10, 398, 'ch398_file10_read')\n",
      "(13, 345, 'ch345_file13_read')\n",
      "(37, 488, 'ch488_file37_read')\n",
      "(31, 495, 'ch495_file31_read')\n",
      "(12, 224, 'ch224_file12_read')\n",
      "(4, 48, 'ch48_file4_read')\n",
      "(4, 461, 'ch461_file4_read')\n",
      "(16, 462, 'ch462_file16_read')\n",
      "(19, 262, 'ch262_file19_read')\n",
      "(2, 82, 'ch82_file2_read')\n",
      "(15, 39, 'ch39_file15_read')\n",
      "(0, 260, 'ch260_file0_read')\n",
      "(7, 479, 'ch479_file7_read')\n",
      "(21, 203, 'ch203_file21_read')\n",
      "(23, 105, 'ch105_file23_read')\n",
      "(11, 417, 'ch417_file11_read')\n",
      "(4, 135, 'ch135_file4_read')\n",
      "(24, 458, 'ch458_file24_read')\n",
      "(26, 390, 'ch390_file26_read')\n",
      "(7, 186, 'ch186_file7_read')\n",
      "(35, 451, 'ch451_file35_read')\n",
      "(24, 59, 'ch59_file24_read')\n",
      "(19, 96, 'ch96_file19_read')\n",
      "(11, 255, 'ch255_file11_read')\n",
      "(23, 419, 'ch419_file23_read')\n",
      "(5, 180, 'ch180_file5_read')\n",
      "(19, 44, 'ch44_file19_read')\n",
      "(20, 275, 'ch275_file20_read')\n",
      "(24, 106, 'ch106_file24_read')\n",
      "(7, 304, 'ch304_file7_read')\n",
      "(12, 441, 'ch441_file12_read')\n",
      "(15, 96, 'ch96_file15_read')\n",
      "(0, 376, 'ch376_file0_read')\n",
      "(25, 21, 'ch21_file25_read')\n",
      "(28, 20, 'ch20_file28_read')\n",
      "(2, 441, 'ch441_file2_read')\n",
      "(10, 203, 'ch203_file10_read')\n",
      "(2, 244, 'ch244_file2_read')\n",
      "(5, 93, 'ch93_file5_read')\n",
      "(26, 414, 'ch414_file26_read')\n",
      "(6, 204, 'ch204_file6_read')\n",
      "(17, 466, 'ch466_file17_read')\n",
      "(6, 22, 'ch22_file6_read')\n",
      "(1, 453, 'ch453_file1_read')\n",
      "(38, 13, 'ch13_file38_read')\n",
      "(12, 96, 'ch96_file12_read')\n",
      "(10, 462, 'ch462_file10_read')\n",
      "(8, 226, 'ch226_file8_read')\n",
      "(30, 469, 'ch469_file30_read')\n",
      "(0, 26, 'ch26_file0_read')\n",
      "(10, 506, 'ch506_file10_read')\n",
      "(2, 259, 'ch259_file2_read')\n",
      "(0, 95, 'ch95_file0_read')\n",
      "(1, 28, 'ch28_file1_read')\n",
      "(16, 57, 'ch57_file16_read')\n",
      "(18, 496, 'ch496_file18_read')\n",
      "(56, 33, 'ch33_file56_read')\n",
      "(6, 484, 'ch484_file6_read')\n",
      "(12, 364, 'ch364_file12_read')\n",
      "(19, 469, 'ch469_file19_read')\n",
      "(29, 452, 'ch452_file29_read')\n",
      "(12, 82, 'ch82_file12_read')\n",
      "(27, 441, 'ch441_file27_read')\n",
      "(1, 59, 'ch59_file1_read')\n",
      "(19, 112, 'ch112_file19_read')\n",
      "(20, 447, 'ch447_file20_read')\n",
      "(21, 47, 'ch47_file21_read')\n",
      "(13, 454, 'ch454_file13_read')\n",
      "(25, 101, 'ch101_file25_read')\n",
      "(7, 91, 'ch91_file7_read')\n",
      "(9, 134, 'ch134_file9_read')\n",
      "(13, 262, 'ch262_file13_read')\n",
      "(2, 31, 'ch31_file2_read')\n",
      "(19, 40, 'ch40_file19_read')\n",
      "(26, 458, 'ch458_file26_read')\n",
      "(21, 246, 'ch246_file21_read')\n",
      "(2, 419, 'ch419_file2_read')\n",
      "(5, 393, 'ch393_file5_read')\n",
      "(13, 57, 'ch57_file13_read')\n",
      "(18, 508, 'ch508_file18_read')\n",
      "(4, 260, 'ch260_file4_read')\n",
      "(27, 364, 'ch364_file27_read')\n",
      "(2, 6, 'ch6_file2_read')\n",
      "(2, 261, 'ch261_file2_read')\n",
      "(4, 32, 'ch32_file4_read')\n",
      "(1, 367, 'ch367_file1_read')\n",
      "(15, 454, 'ch454_file15_read')\n",
      "(9, 296, 'ch296_file9_read')\n",
      "(17, 126, 'ch126_file17_read')\n",
      "(0, 310, 'ch310_file0_read')\n",
      "(6, 132, 'ch132_file6_read')\n",
      "(5, 297, 'ch297_file5_read')\n",
      "(14, 442, 'ch442_file14_read')\n",
      "(11, 98, 'ch98_file11_read')\n",
      "(12, 393, 'ch393_file12_read')\n",
      "(7, 230, 'ch230_file7_read')\n",
      "(18, 21, 'ch21_file18_read')\n",
      "(14, 447, 'ch447_file14_read')\n",
      "(15, 21, 'ch21_file15_read')\n",
      "(0, 237, 'ch237_file0_read')\n",
      "(14, 104, 'ch104_file14_read')\n",
      "(14, 426, 'ch426_file14_read')\n",
      "(26, 31, 'ch31_file26_read')\n",
      "(27, 461, 'ch461_file27_read')\n",
      "(8, 456, 'ch456_file8_read')\n",
      "(20, 452, 'ch452_file20_read')\n",
      "(16, 20, 'ch20_file16_read')\n",
      "(2, 436, 'ch436_file2_read')\n",
      "(4, 255, 'ch255_file4_read')\n",
      "(29, 488, 'ch488_file29_read')\n",
      "(30, 119, 'ch119_file30_read')\n",
      "(14, 105, 'ch105_file14_read')\n",
      "(3, 494, 'ch494_file3_read')\n",
      "(36, 436, 'ch436_file36_read')\n",
      "(8, 46, 'ch46_file8_read')\n",
      "(15, 168, 'ch168_file15_read')\n",
      "(17, 108, 'ch108_file17_read')\n",
      "(13, 132, 'ch132_file13_read')\n",
      "(7, 414, 'ch414_file7_read')\n",
      "(8, 165, 'ch165_file8_read')\n",
      "(3, 419, 'ch419_file3_read')\n",
      "(15, 74, 'ch74_file15_read')\n",
      "(18, 134, 'ch134_file18_read')\n",
      "(41, 436, 'ch436_file41_read')\n",
      "(8, 158, 'ch158_file8_read')\n",
      "(2, 53, 'ch53_file2_read')\n",
      "(34, 20, 'ch20_file34_read')\n",
      "(7, 54, 'ch54_file7_read')\n",
      "(0, 414, 'ch414_file0_read')\n",
      "(14, 84, 'ch84_file14_read')\n",
      "(6, 36, 'ch36_file6_read')\n",
      "(1, 201, 'ch201_file1_read')\n",
      "(1, 426, 'ch426_file1_read')\n",
      "(11, 195, 'ch195_file11_read')\n",
      "(9, 476, 'ch476_file9_read')\n",
      "(29, 96, 'ch96_file29_read')\n",
      "(18, 122, 'ch122_file18_read')\n",
      "(8, 44, 'ch44_file8_read')\n",
      "(24, 485, 'ch485_file24_read')\n",
      "(6, 91, 'ch91_file6_read')\n",
      "(5, 458, 'ch458_file5_read')\n",
      "(15, 92, 'ch92_file15_read')\n",
      "(25, 460, 'ch460_file25_read')\n",
      "(26, 19, 'ch19_file26_read')\n",
      "(11, 81, 'ch81_file11_read')\n",
      "(11, 128, 'ch128_file11_read')\n",
      "(4, 64, 'ch64_file4_read')\n",
      "(17, 414, 'ch414_file17_read')\n",
      "(15, 32, 'ch32_file15_read')\n",
      "(12, 29, 'ch29_file12_read')\n",
      "(11, 393, 'ch393_file11_read')\n",
      "(16, 219, 'ch219_file16_read')\n",
      "(1, 132, 'ch132_file1_read')\n",
      "(0, 320, 'ch320_file0_read')\n",
      "(17, 443, 'ch443_file17_read')\n",
      "(0, 23, 'ch23_file0_read')\n",
      "(7, 400, 'ch400_file7_read')\n",
      "(1, 286, 'ch286_file1_read')\n",
      "(13, 21, 'ch21_file13_read')\n",
      "(8, 444, 'ch444_file8_read')\n",
      "(6, 252, 'ch252_file6_read')\n",
      "(4, 248, 'ch248_file4_read')\n",
      "(14, 117, 'ch117_file14_read')\n",
      "(8, 435, 'ch435_file8_read')\n",
      "(9, 324, 'ch324_file9_read')\n",
      "(2, 496, 'ch496_file2_read')\n",
      "(24, 467, 'ch467_file24_read')\n",
      "(0, 459, 'ch459_file0_read')\n",
      "(2, 28, 'ch28_file2_read')\n",
      "(9, 168, 'ch168_file9_read')\n",
      "(5, 269, 'ch269_file5_read')\n",
      "(12, 335, 'ch335_file12_read')\n",
      "(11, 353, 'ch353_file11_read')\n",
      "(12, 18, 'ch18_file12_read')\n",
      "(5, 259, 'ch259_file5_read')\n",
      "(7, 353, 'ch353_file7_read')\n",
      "(1, 196, 'ch196_file1_read')\n",
      "(1, 64, 'ch64_file1_read')\n",
      "(13, 53, 'ch53_file13_read')\n",
      "(16, 123, 'ch123_file16_read')\n",
      "(1, 400, 'ch400_file1_read')\n",
      "(12, 248, 'ch248_file12_read')\n",
      "(5, 276, 'ch276_file5_read')\n",
      "(19, 444, 'ch444_file19_read')\n",
      "(14, 21, 'ch21_file14_read')\n",
      "(4, 312, 'ch312_file4_read')\n",
      "(3, 495, 'ch495_file3_read')\n",
      "(22, 396, 'ch396_file22_read')\n",
      "(44, 20, 'ch20_file44_read')\n",
      "(39, 40, 'ch40_file39_read')\n",
      "(15, 247, 'ch247_file15_read')\n",
      "(14, 112, 'ch112_file14_read')\n",
      "(18, 443, 'ch443_file18_read')\n",
      "(15, 483, 'ch483_file15_read')\n",
      "(3, 248, 'ch248_file3_read')\n",
      "(7, 251, 'ch251_file7_read')\n",
      "(29, 29, 'ch29_file29_read')\n",
      "(17, 378, 'ch378_file17_read')\n",
      "(10, 40, 'ch40_file10_read')\n",
      "(11, 40, 'ch40_file11_read')\n",
      "(25, 56, 'ch56_file25_read')\n",
      "(22, 114, 'ch114_file22_read')\n",
      "(3, 399, 'ch399_file3_read')\n",
      "(3, 207, 'ch207_file3_read')\n",
      "(23, 472, 'ch472_file23_read')\n",
      "(28, 443, 'ch443_file28_read')\n",
      "(20, 280, 'ch280_file20_read')\n",
      "(21, 62, 'ch62_file21_read')\n",
      "(5, 335, 'ch335_file5_read')\n",
      "(34, 21, 'ch21_file34_read')\n",
      "(14, 503, 'ch503_file14_read')\n",
      "(20, 56, 'ch56_file20_read')\n",
      "(10, 247, 'ch247_file10_read')\n",
      "(6, 467, 'ch467_file6_read')\n",
      "(6, 154, 'ch154_file6_read')\n",
      "(17, 31, 'ch31_file17_read')\n",
      "(9, 453, 'ch453_file9_read')\n",
      "(1, 106, 'ch106_file1_read')\n",
      "(2, 447, 'ch447_file2_read')\n",
      "(15, 28, 'ch28_file15_read')\n",
      "(23, 246, 'ch246_file23_read')\n",
      "(11, 442, 'ch442_file11_read')\n",
      "(0, 274, 'ch274_file0_read')\n",
      "(15, 268, 'ch268_file15_read')\n",
      "(13, 126, 'ch126_file13_read')\n",
      "(16, 439, 'ch439_file16_read')\n",
      "(16, 431, 'ch431_file16_read')\n",
      "(0, 146, 'ch146_file0_read')\n",
      "(0, 500, 'ch500_file0_read')\n",
      "(2, 122, 'ch122_file2_read')\n"
     ]
    }
   ],
   "source": [
    "p = Pool(args[\"ncores\"])\n",
    "## one can not access a read in parallel (deadlock for whatever reason)\n",
    "## therfore prepare input parameters outside of map\n",
    "input_params = [(read.query_name, read.get_reference_positions()) for read in reads]\n",
    "try:\n",
    "    results = p.map(basecall_read, input_params)\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers, seqs, stats = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = pandas.DataFrame(list(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = stats.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d_caller       29575648\n",
       "d_metrichor    14048622\n",
       "length         28996266\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Performance: 47.501%\n"
     ]
    }
   ],
   "source": [
    "print(\"Relative Performance: {0:5.3f}%\".format(stats[\"d_metrichor\"] * 100 /float(stats[\"d_caller\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasta_file_called = \"{0}.called.fa\".format(args[\"out_basename\"])\n",
    "with open(fasta_file_called, 'w') as f: \n",
    "    for header, seq in zip(headers, seqs): \n",
    "        f.write(\">\" + header + \"\\n\")\n",
    "        f.write(seq + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index 12:42:30] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 12:42:30] Index already exists. Loading from file.\n",
      "[Index 12:42:31] Secondary index already exists. Loading from file.\n",
      "[Index 12:42:31] Index loaded in 0.44 sec.\n",
      "[Index 12:42:31] Memory consumption: [currentRSS = 516 MB, peakRSS = 15804 MB]\n",
      "\n",
      "[Run 12:42:31] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 12:42:31] Reference genome is assumed to be linear.\n",
      "[Run 12:42:31] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 12:42:31] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 12:42:31] Batch of 5709 reads (34 MiB) loaded in 0.30 sec. (33080488 bases)\n",
      "[ProcessReads 12:42:31] Memory consumption: [currentRSS = 551 MB, peakRSS = 15804 MB]\n",
      "[ProcessReads 12:42:31] Using 62 threads.\n",
      "[ProcessReads 12:42:33] [CPU time: 99.89 sec, RSS: 557 MB] Read: 5709/5709 (100.00%) [m: 0, u: 5709]                                                               \n",
      "\n",
      "[ProcessReads 12:42:33] Memory consumption: [currentRSS = 557 MB, peakRSS = 15804 MB]\n",
      "\n",
      "[ProcessReads 12:42:33] All reads processed in 99.92 sec (or 1.67 CPU min).\n"
     ]
    }
   ],
   "source": [
    "sam_file_called = \"{0}.called.sam\".format(args[\"out_basename\"])\n",
    "graphmap(ref_file, fasta_file_called, sam_file_called, args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_calling.called.sorted.bam'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sam(\"{0}.called\".format(args[\"out_basename\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH einser ipython2",
   "language": "",
   "name": "rik_ssh_einser_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
