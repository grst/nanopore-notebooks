{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "import pickle\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMERS = 3\n",
    "NSTATES = 4**NMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events.template.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_calling\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/mouse_ref.fa\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "    \"ncores\": 4\n",
    "}\n",
    "\n",
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_calling\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "#     \"ncores\": 62\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = sorted(zip(*[HMM_PARAMS[\"kmers\"], HMM_PARAMS[\"means\"], HMM_PARAMS[\"stdv\"]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 1/4. if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)] else 0.\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat0(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (9/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1 or move=2\"\"\"\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    n_components = len(all_kmers)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(all_kmers):\n",
    "        for i, to_kmer in enumerate(all_kmers):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                \"\"\"move=2\"\"\"\n",
    "                p = (20/50.) * (1/16.)\n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (29/50.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/50.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = ghmm.Float()  # emission domain of this model\n",
    "\n",
    "def mk_model():\n",
    "    # example code for a continuous HMM with gaussian emissions\n",
    "\n",
    "\n",
    "\n",
    "    A = mk_transmat2(NMERS)\n",
    "    B = [[x[1], x[2]] for x in HMM_PARAMS]   # parameters of emission distributions in pairs of (mu, sigma)\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianEmissionHMM(N=64)\n",
      "  state 0 (initial=0.02, mu=70.17, sigma=3.84)\n",
      "    Transitions: ->0 (0.03), ->1 (0.03), ->2 (0.03), ->3 (0.03), ->4 (0.03), ->5 (0.03), ->6 (0.03), ->7 (0.03), ->8 (0.03), ->9 (0.03), ->10 (0.03), ->11 (0.03), ->12 (0.03), ->13 (0.03), ->14 (0.03), ->15 (0.03)\n",
      "  state 1 (initial=0.02, mu=63.14, sigma=3.47)\n",
      "    Transitions: ->1 (0.02), ->4 (0.14), ->5 (0.14), ->6 (0.14), ->7 (0.14), ->16 (0.03), ->17 (0.03), ->18 (0.03), ->19 (0.03), ->20 (0.03), ->21 (0.03), ->22 (0.03), ->23 (0.03), ->24 (0.03), ->25 (0.03), ->26 (0.03), ->27 (0.03), ->28 (0.03), ->29 (0.03), ->30 (0.03), ->31 (0.03)\n",
      "\n",
      "  ...\n",
      "\n",
      "  state 62 (initial=0.02, mu=53.52, sigma=2.85)\n",
      "    Transitions: ->32 (0.03), ->33 (0.03), ->34 (0.03), ->35 (0.03), ->36 (0.03), ->37 (0.03), ->38 (0.03), ->39 (0.03), ->40 (0.03), ->41 (0.03), ->42 (0.03), ->43 (0.03), ->44 (0.03), ->45 (0.03), ->46 (0.03), ->47 (0.03), ->56 (0.14), ->57 (0.14), ->58 (0.14), ->59 (0.14), ->62 (0.02)\n",
      "  state 63 (initial=0.02, mu=49.86, sigma=2.78)\n",
      "    Transitions: ->48 (0.03), ->49 (0.03), ->50 (0.03), ->51 (0.03), ->52 (0.03), ->53 (0.03), ->54 (0.03), ->55 (0.03), ->56 (0.03), ->57 (0.03), ->58 (0.03), ->59 (0.03), ->60 (0.03), ->61 (0.03), ->62 (0.03), ->63 (0.03)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = mk_model()\n",
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    all_kmers = [x[0] for x in HMM_PARAMS]\n",
    "    kmers = [all_kmers[x] for x in states]\n",
    "    seq = [kmer[NMERS/2] for kmer in kmers]\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(means):\n",
    "    seq = ghmm.EmissionSequence(F, means)\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'TTTGTGTGT'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict([44.2, 44.3, 56, 58.2, 56.2, 58.1, 58.2, 60, 30.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>mmusMT_PCR1']\n",
      "GTTAATGTAGCTTAATAACAAAGCAAAGCACTGAAAATGCTTAGATGGATAATTGTATCCCATAAACACAAAGGTTTGGTCCTGGCCTTATAATTAATTA\n"
     ]
    }
   ],
   "source": [
    "ref_file = args[\"ref\"]\n",
    "test = !cat {ref_file} | grep \">\"\n",
    "print(test)\n",
    "ref = !cat {ref_file} | grep -v \">\"\n",
    "ref = ref[0]\n",
    "print(ref[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastq_file = \"{0}.fastq\".format(args[\"out_basename\"])\n",
    "mk_fastq(fastq_file, file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index 12:59:56] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 12:59:56] Index already exists. Loading from file.\n",
      "[Index 12:59:58] Secondary index already exists. Loading from file.\n",
      "[Index 12:59:59] Index loaded in 0.40 sec.\n",
      "[Index 12:59:59] Memory consumption: [currentRSS = 513 MB, peakRSS = 513 MB]\n",
      "\n",
      "[Run 12:59:59] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 12:59:59] Reference genome is assumed to be linear.\n",
      "[Run 12:59:59] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 12:59:59] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 12:59:59] Batch of 81 reads (0 MiB) loaded in 0.01 sec. (19948664 bases)\n",
      "[ProcessReads 12:59:59] Memory consumption: [currentRSS = 514 MB, peakRSS = 514 MB]\n",
      "[ProcessReads 12:59:59] Using 4 threads.\n",
      "[ProcessReads 13:00:00] [CPU time: 3.46 sec, RSS: 536 MB] Read: 81/81 (100.00%) [m: 80, u: 1]                                                                      \n",
      "\n",
      "[ProcessReads 13:00:00] Memory consumption: [currentRSS = 536 MB, peakRSS = 581 MB]\n",
      "\n",
      "[ProcessReads 13:00:00] All reads processed in 3.46 sec (or 0.06 CPU min).\n"
     ]
    }
   ],
   "source": [
    "sam_file = \"{0}.sam\".format(args[\"out_basename\"])\n",
    "graphmap(ref_file, fastq_file, sam_file, args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[samopen] SAM header is present: 1 sequences.\r\n"
     ]
    }
   ],
   "source": [
    "bam_file = prepare_sam(args[\"out_basename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samfile = pysam.AlignmentFile(bam_file)\n",
    "reads  = [x for x in samfile.fetch()]\n",
    "len(reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_read(read_name): \n",
    "    file_id, channel_id = get_file_and_channel(read_name)\n",
    "    file_obj = get_file(channel_id, file_id)      \n",
    "    events = [x[\"mean\"] for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    seq = ghmm.EmissionSequence(F, events)\n",
    "    model.baumWelch(seq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(params):\n",
    "    read_name, ref_pos = params\n",
    "    file_id, channel_id = get_file_and_channel(read_name)\n",
    "#     sys.stdout.write(\"{0} {1} {2}\\n\".format(file_id, channel_id, read_name))\n",
    "#     sys.stdout.flush()\n",
    "    \n",
    "    file_obj = get_file(channel_id, file_id)\n",
    "      \n",
    "    events = [x[\"mean\"] for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    metrichor_seq = file_obj[\"fastq\"].split(\"\\n\")[1]\n",
    "    ref_seq = \"\".join([ref[x] for x in ref_pos])\n",
    "    seq = ghmm.EmissionSequence(F, events)\n",
    "    called_seq = predict(events)\n",
    "    \n",
    "    stats = {\n",
    "        \"d_metrichor\": int(editdistance.eval(ref_seq, metrichor_seq)),\n",
    "        \"d_caller\": int(editdistance.eval(ref_seq, called_seq)), \n",
    "        \"length\": len(ref_seq),\n",
    "    }\n",
    "\n",
    "    return (read_name, called_seq, stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## one can not access a read in parallel (deadlock for whatever reason)\n",
    "## therfore prepare input parameters outside of map\n",
    "input_params = [(read.query_name, read.get_reference_positions()) for read in reads]\n",
    "read_names = [x[0] for x in input_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 3.750000%"
     ]
    }
   ],
   "source": [
    "for i, read in enumerate(read_names): \n",
    "    sys.stdout.write('\\rdone {0:%}'.format(i/float(len(read_names))))\n",
    "    train_read(read)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction: \")\n",
    "results = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(basecall_read, input_params), 1):\n",
    "        results.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(input_params))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "headers, seqs, stats = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = pandas.DataFrame(list(stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = stats.sum(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Relative Performance: {0:5.3f}%\".format(stats[\"d_metrichor\"] * 100 /float(stats[\"d_caller\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ## Random control\n",
    "# import random\n",
    "# seqs = [\"\".join([random.choice(\"ACGT\") for _ in range(len(read))]) for read in seqs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fasta_file_called = \"{0}.called.fa\".format(args[\"out_basename\"])\n",
    "with open(fasta_file_called, 'w') as f: \n",
    "    for header, seq in zip(headers, seqs): \n",
    "        f.write(\">\" + header + \"\\n\")\n",
    "        f.write(seq + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sam_file_called = \"{0}.called.sam\".format(args[\"out_basename\"])\n",
    "graphmap(ref_file, fasta_file_called, sam_file_called, args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_sam(\"{0}.called\".format(args[\"out_basename\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
