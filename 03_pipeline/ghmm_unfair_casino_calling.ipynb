{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "from collections import OrderedDict\n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "from itertools import product as iterproduct, chain\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "import random\n",
    "from nbwrapper import getargs\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_validation.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_lib.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/analysis_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/bin/anaconda/lib/python2.7/site-packages/nbwrapper.py:31: RuntimeWarning: no arguments passed!\n",
      "  warnings.warn(\"no arguments passed!\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events.template.pickle\",\n",
    "    \"raw\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_raw.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_calling\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/mouse_ref.fa\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_hmm_params_raw_3mer.pickle\",\n",
    "    \"ncores\": 60,\n",
    "    \"nmers\": 3,\n",
    "}\n",
    "\n",
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_calling\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "#     \"ncores\": 62,\n",
    "#     \"nmers\": 3,\n",
    "#     \"multivariate\": True\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "NMERS = int(args[\"nmers\"])\n",
    "NSTATES = 4**NMERS\n",
    "args[\"ncores\"] = int(args[\"ncores\"])\n",
    "MEAN_LENGTH = 175"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = OrderedDict(HMM_PARAMS)\n",
    "ALL_KMERS = [\"\".join(x) for x in iterproduct(\"ACGT\", repeat=NMERS)]\n",
    "assert HMM_PARAMS.keys() == ALL_KMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_transmat1(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    p_move = float(1)/MEAN_LENGTH\n",
    "    p_stay = 1-p_move\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                p = p_move * 1/4.\n",
    "            elif from_kmer == to_kmer: \n",
    "                p = p_stay\n",
    "            else: \n",
    "                p = 0\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    p_move = float(1)/MEAN_LENGTH\n",
    "    p_stay = 1-p_move\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                p = p_move * 1/3. * 1/16. \n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                p = p_move *2/3. * 1/4.\n",
    "            elif from_kmer == to_kmer: \n",
    "                p = p_stay\n",
    "            else: \n",
    "                p = 0\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "mk_transmat = mk_transmat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "F = ghmm.Float()  # emission domain of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_model_simple(): \n",
    "    \"\"\" simple model, only taking the means into account. \"\"\"\n",
    "    A = mk_transmat(NMERS)\n",
    "    B = [ [float(df[['mean']].mean()), float(df[['mean']].std())] #mu1, stdv\n",
    "            for df in HMM_PARAMS.values()]   # parameters of emission distributions in pairs of (mu, sigma)\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_model():\n",
    "    return mk_model_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianEmissionHMM(N=64)\n",
      "  state 0 (initial=0.02, mu=302.24, sigma=17.15)\n",
      "    Transitions: ->0 (0.00), ->1 (0.00), ->2 (0.00), ->3 (0.00)\n",
      "  state 1 (initial=0.02, mu=272.18, sigma=15.59)\n",
      "    Transitions: ->1 (0.99), ->4 (0.00), ->5 (0.00), ->6 (0.00), ->7 (0.00)\n",
      "\n",
      "  ...\n",
      "\n",
      "  state 62 (initial=0.02, mu=230.94, sigma=12.95)\n",
      "    Transitions: ->56 (0.00), ->57 (0.00), ->58 (0.00), ->59 (0.00), ->62 (0.99)\n",
      "  state 63 (initial=0.02, mu=215.48, sigma=12.62)\n",
      "    Transitions: ->60 (0.00), ->61 (0.00), ->62 (0.00), ->63 (0.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = mk_model()\n",
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def collapse_seq(seq):\n",
    "    if len(seq) == 0: \n",
    "        return []\n",
    "    collapsed = [seq[0]] + [seq[i] for i in range(1, len(seq)) if seq[i-1] != seq[i]]\n",
    "    return collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    kmers = [ALL_KMERS[x] for x in states]\n",
    "    seq = [kmer[NMERS/2] for kmer in kmers]\n",
    "    seq = collapse_seq(seq)\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def predict(raw):\n",
    "    \"\"\"mixed is a set of tuples (event_mean, event_stdv)\"\"\"\n",
    "    seq = ghmm.EmissionSequence(F, raw.tolist())\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "s = model.sampleSingle(1000)\n",
    "s = np.array([x for x in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TCTGATA'"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>mmusMT_PCR1']\n",
      "GTTAATGTAGCTTAATAACAAAGCAAAGCACTGAAAATGCTTAGATGGATAATTGTATCCCATAAACACAAAGGTTTGGTCCTGGCCTTATAATTAATTA\n"
     ]
    }
   ],
   "source": [
    "ref_file = args[\"ref\"]\n",
    "test = !cat {ref_file} | grep \">\"\n",
    "print(test)\n",
    "ref = !cat {ref_file} | grep -v \">\"\n",
    "ref = ref[0]\n",
    "print(ref[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "raw_data = pickle.load(open(args[\"raw\"], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(file_obj):\n",
    "    try:\n",
    "        read_min = file_obj[\"events\"][\"template.start\"].iloc[0]\n",
    "        read_max = file_obj[\"events\"][\"template.end\"].iloc[-1]\n",
    "    except KeyError: \n",
    "        read_min = file_obj[\"events\"][\"start\"].iloc[0]\n",
    "        read_max = file_obj[\"events\"][\"end\"].iloc[-1]\n",
    "    raw = raw_data[file_obj[\"channel\"]]\n",
    "    for i in range(read_min, read_max): \n",
    "        if np.isnan(raw[i]): \n",
    "            ## raw data now available\n",
    "            return (file_obj[\"channel\"], file_obj[\"file_id\"], None)\n",
    "        if raw[i] < 150: raw[i] = 150\n",
    "        if raw[i] > 450: raw[i] = 450\n",
    "#     raw_new = np.copy(raw)\n",
    "    for i in range(read_min, read_max-50):\n",
    "        raw[i] = np.mean(raw[i:i+50])      \n",
    "    called_seq = predict(raw[read_min:read_max])\n",
    "    return (file_obj[\"channel\"], file_obj[\"file_id\"], called_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for file_obj in file_data:\n",
    "#     print(file_obj[\"file_id\"], file_obj[\"channel\"])\n",
    "#     print(basecall_read(file_obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: \n",
      "done 100.000000%"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: \")\n",
    "results = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(basecall_read, file_data), 1):\n",
    "        results.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2163, 921)\n",
      "(2519, 1168)\n",
      "(1640, 754)\n",
      "(2479, 1116)\n",
      "(3099, 1380)\n",
      "(2768, 1246)\n",
      "(3812, 1614)\n",
      "(4638, 2519)\n",
      "(5079, 2359)\n",
      "(5330, 2104)\n",
      "(5835, 2658)\n",
      "(6431, 2931)\n",
      "(6455, 2681)\n",
      "(4948, 1972)\n",
      "(7998, 3517)\n",
      "(7598, 3187)\n",
      "(6690, 3219)\n",
      "(7115, 3171)\n",
      "(9207, 4050)\n",
      "(7670, 3102)\n",
      "(10717, 4866)\n",
      "(13207, 6292)\n",
      "(11731, 5322)\n",
      "(14835, 6709)\n",
      "(12993, 6570)\n",
      "(7726, 6009)\n",
      "(14301, 6770)\n",
      "(13690, 6117)\n",
      "(14021, 6642)\n",
      "(15391, 6831)\n",
      "(15483, 6636)\n",
      "(15239, 6867)\n",
      "(12493, 5700)\n",
      "(14978, 6827)\n",
      "(14585, 6255)\n",
      "(13123, 6329)\n",
      "(16776, 7605)\n",
      "(10285, 4556)\n",
      "(14692, 6831)\n",
      "(14963, 6393)\n",
      "(14664, 6696)\n",
      "(16996, 7379)\n",
      "(15426, 6586)\n",
      "(10803, 4725)\n",
      "(15870, 6578)\n",
      "(15222, 7058)\n",
      "(16740, 7380)\n",
      "(15248, 6602)\n",
      "(14707, 6734)\n",
      "(11410, 4496)\n",
      "(17080, 7450)\n",
      "(15709, 6907)\n",
      "(15622, 6895)\n",
      "(17930, 7818)\n",
      "(16453, 6878)\n",
      "(16625, 7596)\n",
      "(16865, 6842)\n",
      "(12902, 5256)\n",
      "(17568, 7621)\n",
      "(13836, 6256)\n",
      "(15035, 6870)\n",
      "(16591, 7077)\n",
      "(15927, 6757)\n",
      "(16003, 6672)\n",
      "(13997, 5829)\n",
      "(18144, 7754)\n",
      "(17253, 7251)\n",
      "(17052, 6917)\n",
      "(24971, 10862)\n",
      "(18177, 7233)\n",
      "(19500, 7132)\n",
      "(33654, 14176)\n",
      "(18516, 7086)\n"
     ]
    }
   ],
   "source": [
    "for ch, fid, seq in results: \n",
    "    fo = get_file(ch, fid)\n",
    "    if seq is not None:\n",
    "        print(len(seq), len(fo[\"fastq\"].split(\"\\n\")[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "types = [\"metrichor\", \"called\", \"random\"]\n",
    "fasta_files = {t: \"{0}.{1}.fa\".format(args[\"out_basename\"], t) for t in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "## metrichor fasta\n",
    "with open(fasta_files[\"metrichor\"], 'w') as f: \n",
    "    for file_obj in file_data: \n",
    "        f.write(\">ch{0}_file{1}_metrichor\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "        f.write(file_obj[\"fastq\"].split(\"\\n\")[1] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "## called fasta/random fasta\n",
    "with open(fasta_files[\"called\"], 'w') as f: \n",
    "    with open(fasta_files[\"random\"], 'w') as fr:\n",
    "        for channel, file_id, seq in results: \n",
    "            if seq is not None:\n",
    "                f.write(\">ch{0}_file{1}_called\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "                fr.write(\">ch{0}_file{1}_random\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "                f.write(seq + \"\\n\")\n",
    "                fr.write(\"\".join([random.choice(\"ACGT\") for _ in range(len(seq))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index 13:54:27] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 13:54:27] Index already exists. Loading from file.\n",
      "[Index 13:54:27] Secondary index already exists. Loading from file.\n",
      "[Index 13:54:27] Index loaded in 0.47 sec.\n",
      "[Index 13:54:27] Memory consumption: [currentRSS = 515 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[Run 13:54:27] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 13:54:27] Reference genome is assumed to be linear.\n",
      "[Run 13:54:27] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 13:54:27] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 13:54:27] Batch of 81 reads (0 MiB) loaded in 0.00 sec. (30909608 bases)\n",
      "[ProcessReads 13:54:27] Memory consumption: [currentRSS = 515 MB, peakRSS = 6172 MB]\n",
      "[ProcessReads 13:54:27] Using 60 threads.\n",
      "[ProcessReads 13:54:28] [CPU time: 12.35 sec, RSS: 528 MB] Read: 81/81 (100.00%) [m: 80, u: 1]                                                                     \n",
      "\n",
      "[ProcessReads 13:54:28] Memory consumption: [currentRSS = 528 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[ProcessReads 13:54:28] All reads processed in 12.35 sec (or 0.21 CPU min).\n",
      "[Index 13:54:31] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 13:54:31] Index already exists. Loading from file.\n",
      "[Index 13:54:31] Secondary index already exists. Loading from file.\n",
      "[Index 13:54:31] Index loaded in 0.47 sec.\n",
      "[Index 13:54:31] Memory consumption: [currentRSS = 515 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[Run 13:54:31] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 13:54:31] Reference genome is assumed to be linear.\n",
      "[Run 13:54:31] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 13:54:31] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 13:54:31] Batch of 73 reads (0 MiB) loaded in 0.01 sec. (37942440 bases)\n",
      "[ProcessReads 13:54:31] Memory consumption: [currentRSS = 516 MB, peakRSS = 6172 MB]\n",
      "[ProcessReads 13:54:31] Using 60 threads.\n",
      "[ProcessReads 13:54:32] [CPU time: 10.38 sec, RSS: 526 MB] Read: 73/73 (100.00%) [m: 34, u: 39]                                                                    \n",
      "\n",
      "[ProcessReads 13:54:32] Memory consumption: [currentRSS = 526 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[ProcessReads 13:54:32] All reads processed in 10.40 sec (or 0.17 CPU min).\n",
      "[Index 13:54:35] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 13:54:35] Index already exists. Loading from file.\n",
      "[Index 13:54:35] Secondary index already exists. Loading from file.\n",
      "[Index 13:54:35] Index loaded in 0.48 sec.\n",
      "[Index 13:54:35] Memory consumption: [currentRSS = 515 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[Run 13:54:35] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 13:54:35] Reference genome is assumed to be linear.\n",
      "[Run 13:54:35] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 13:54:35] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 13:54:35] Batch of 73 reads (0 MiB) loaded in 0.01 sec. (14701736 bases)\n",
      "[ProcessReads 13:54:35] Memory consumption: [currentRSS = 516 MB, peakRSS = 6172 MB]\n",
      "[ProcessReads 13:54:35] Using 60 threads.\n",
      "[ProcessReads 13:54:37] [CPU time: 28.89 sec, RSS: 544 MB] Read: 73/73 (100.00%) [m: 70, u: 3]                                                                     \n",
      "\n",
      "[ProcessReads 13:54:37] Memory consumption: [currentRSS = 544 MB, peakRSS = 6172 MB]\n",
      "\n",
      "[ProcessReads 13:54:37] All reads processed in 28.91 sec (or 0.48 CPU min).\n"
     ]
    }
   ],
   "source": [
    "for t in types: \n",
    "    sam_file = \"{0}.{1}.sam\".format(args[\"out_basename\"], t)\n",
    "    graphmap(ref_file, fasta_files[t], sam_file, args[\"ncores\"])\n",
    "    prepare_sam(\"{0}.{1}\".format(args[\"out_basename\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "def mk_stat(t):\n",
    "    samfile = pysam.AlignmentFile(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t))\n",
    "    sst = samstats(samfile, ref)\n",
    "    return pandas.DataFrame(sst.print_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    stats = p.map(mk_stat, types)\n",
    "    p.close()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['metrichor', 'called', 'random']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style='float: left;'><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mapped_reads/total_reads</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>98.765432%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>significant_reads/total_reads</td>\n",
       "      <td>68</td>\n",
       "      <td>81</td>\n",
       "      <td>83.950617%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mapped_nts/total_nts</td>\n",
       "      <td>387166</td>\n",
       "      <td>454059</td>\n",
       "      <td>85.267774%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editdistance/alignment_length</td>\n",
       "      <td>201132</td>\n",
       "      <td>442591</td>\n",
       "      <td>45.444214%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alignment_score/alignment_length</td>\n",
       "      <td>319854</td>\n",
       "      <td>442591</td>\n",
       "      <td>72.268528%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNPs/mapped_nts</td>\n",
       "      <td>78814</td>\n",
       "      <td>387166</td>\n",
       "      <td>20.356643%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ins/mapped_nts</td>\n",
       "      <td>66821</td>\n",
       "      <td>387166</td>\n",
       "      <td>17.259005%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>del/mapped_nts</td>\n",
       "      <td>55425</td>\n",
       "      <td>387166</td>\n",
       "      <td>14.315565%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div><div style='float: left;'><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mapped_reads/total_reads</td>\n",
       "      <td>34</td>\n",
       "      <td>73</td>\n",
       "      <td>46.575342%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>significant_reads/total_reads</td>\n",
       "      <td>2</td>\n",
       "      <td>73</td>\n",
       "      <td>2.739726%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mapped_nts/total_nts</td>\n",
       "      <td>284728</td>\n",
       "      <td>371986</td>\n",
       "      <td>76.542666%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editdistance/alignment_length</td>\n",
       "      <td>181581</td>\n",
       "      <td>300289</td>\n",
       "      <td>60.468748%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alignment_score/alignment_length</td>\n",
       "      <td>-70760</td>\n",
       "      <td>300289</td>\n",
       "      <td>-23.563967%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNPs/mapped_nts</td>\n",
       "      <td>78762</td>\n",
       "      <td>284728</td>\n",
       "      <td>27.662190%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ins/mapped_nts</td>\n",
       "      <td>87237</td>\n",
       "      <td>284728</td>\n",
       "      <td>30.638715%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>del/mapped_nts</td>\n",
       "      <td>15561</td>\n",
       "      <td>284728</td>\n",
       "      <td>5.465216%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div><div style='float: left;'><div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mapped_reads/total_reads</td>\n",
       "      <td>70</td>\n",
       "      <td>73</td>\n",
       "      <td>95.890411%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>significant_reads/total_reads</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000000%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mapped_nts/total_nts</td>\n",
       "      <td>674541</td>\n",
       "      <td>887570</td>\n",
       "      <td>75.998625%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>editdistance/alignment_length</td>\n",
       "      <td>444666</td>\n",
       "      <td>712420</td>\n",
       "      <td>62.416271%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>alignment_score/alignment_length</td>\n",
       "      <td>-227223</td>\n",
       "      <td>712420</td>\n",
       "      <td>-31.894529%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SNPs/mapped_nts</td>\n",
       "      <td>193758</td>\n",
       "      <td>674541</td>\n",
       "      <td>28.724421%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ins/mapped_nts</td>\n",
       "      <td>212976</td>\n",
       "      <td>674541</td>\n",
       "      <td>31.573470%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>del/mapped_nts</td>\n",
       "      <td>37879</td>\n",
       "      <td>674541</td>\n",
       "      <td>5.615522%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div></div>"
      ],
      "text/plain": [
       "<__main__.side_by_side instance at 0x7f489bb5b050>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(types)\n",
    "side_by_side(*stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "for t, df in zip(types, stats):\n",
    "    with open(\"{0}.stats.{1}.html\".format(args[\"out_basename\"], t), 'w') as f:\n",
    "        f.write(df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "# def score_consensus(t):\n",
    "#     consensus = mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t), ref_file)\n",
    "#     return(consensus)\n",
    "#     consensus = consensus.split(\"\\n\")[1].to_upper()\n",
    "#     score = needle(ref, consensus)\n",
    "#     return (consensus, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "# p = Pool(args[\"ncores\"])\n",
    "# try:\n",
    "#     consensus = p.map(score_consensus, types)\n",
    "#     p.close()\n",
    "# except KeyboardInterrupt:\n",
    "#     p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "# consensus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": [
    "# mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], \"metrichor\"), ref_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "breakpoint": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH einser ipython2",
   "language": "",
   "name": "rik_ssh_einser_python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
