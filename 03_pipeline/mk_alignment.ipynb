{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nbwrapper import getargs\n",
    "from pprint import pprint\n",
    "from multiprocessing import Pool, Value\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "from itertools import repeat, count, product, chain\n",
    "import sys\n",
    "import pysam\n",
    "import os.path\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/bin/anaconda3/lib/python3.4/site-packages/nbwrapper.py:31: RuntimeWarning: no arguments passed!\n",
      "  warnings.warn(\"no arguments passed!\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "args = getargs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## for testing only\n",
    "args = {\n",
    "    \"events\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events.2D.pickle\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/mouse_ref.fa\",\n",
    "    \"out_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_alignment\",\n",
    "    \"ncores\": 24\n",
    "}\n",
    "\n",
    "# args = {\n",
    "#     \"events\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events.pickle\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "#     \"out_basename\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_alignment\",\n",
    "#     \"ncores\": 24\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMER = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ibis/gregor.sturm/nanopore/own/notebooks\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])\n",
    "assert os.path.isfile(args[\"ref\"])\n",
    "assert args[\"ncores\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['>mmusMT_PCR1']\n",
      "GTTAATGTAGCTTAATAACAAAGCAAAGCACTGAAAATGCTTAGATGGATAATTGTATCCCATAAACACAAAGGTTTGGTCCTGGCCTTATAATTAATTA\n"
     ]
    }
   ],
   "source": [
    "ref_file = args[\"ref\"]\n",
    "test = !cat {ref_file} | grep \">\"\n",
    "print(test)\n",
    "ref = !cat {ref_file} | grep -v \">\"\n",
    "ref = ref[0]\n",
    "print(ref[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fastq_file = \"{0}.fastq\".format(args[\"out_basename\"])\n",
    "mk_fastq(fastq_file, file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Index 13:07:06] Running in fast and sensitive mode. Two indexes will be used (double memory consumption).\n",
      "[Index 13:07:06] Index already exists. Loading from file.\n",
      "[Index 13:07:07] Secondary index already exists. Loading from file.\n",
      "[Index 13:07:07] Index loaded in 0.49 sec.\n",
      "[Index 13:07:07] Memory consumption: [currentRSS = 515 MB, peakRSS = 515 MB]\n",
      "\n",
      "[Run 13:07:07] Automatically setting the maximum allowed number of regions: max. 500, attempt to reduce after 100\n",
      "[Run 13:07:07] Reference genome is assumed to be linear.\n",
      "[Run 13:07:07] Only one alignment will be reported per mapped read.\n",
      "[ProcessReads 13:07:07] Reads will be loaded in batches of up to 200 MB in size.\n",
      "[ProcessReads 13:07:07] Batch of 51 reads (0 MiB) loaded in 0.00 sec. (27526296 bases)\n",
      "[ProcessReads 13:07:07] Memory consumption: [currentRSS = 516 MB, peakRSS = 516 MB]\n",
      "[ProcessReads 13:07:07] Using 24 threads.\n",
      "[ProcessReads 13:07:07] [CPU time: 4.71 sec, RSS: 520 MB] Read: 51/51 (100.00%) [m: 51, u: 0]                                                                      \n",
      "\n",
      "[ProcessReads 13:07:07] Memory consumption: [currentRSS = 520 MB, peakRSS = 653 MB]\n",
      "\n",
      "[ProcessReads 13:07:07] All reads processed in 4.72 sec (or 0.08 CPU min).\n"
     ]
    }
   ],
   "source": [
    "sam_file = \"{0}.sam\".format(args[\"out_basename\"])\n",
    "graphmap(ref_file, fastq_file, sam_file, args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[samopen] SAM header is present: 1 sequences.\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_alignment.sorted.bam'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sam(args[\"out_basename\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samfile = pysam.AlignmentFile(\"{0}.sorted.bam\".format(args[\"out_basename\"]))\n",
    "samreads = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(file_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads  = [x for x in samfile.fetch()]\n",
    "len(reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AlignmentEndException(Exception):\n",
    "    pass\n",
    "\n",
    "def event_indexes(pairing_seq, offset):\n",
    "    \"\"\" get the next entries from the pairing array\n",
    "    such that k non-gap characters are contained\"\"\"\n",
    "    count = 0\n",
    "    kmer = []\n",
    "    for i in range(offset, len(pairing_seq)): \n",
    "        if count == NMER: break\n",
    "        if pairing_seq[i] is not None:\n",
    "            count += 1\n",
    "            kmer.append(i)\n",
    "    if len(kmer) != NMER: \n",
    "        raise AlignmentEndException\n",
    "    return kmer\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gapmove(to_move, seq, offset):\n",
    "    \"\"\"move by 'move' (from metrichor) in the aligned sequence. \n",
    "    additionally increase index to compensate for each gap\n",
    "    \"\"\"\n",
    "    move = to_move\n",
    "    for i in seq[offset:]: \n",
    "        if i is None: \n",
    "            move += 1\n",
    "        else:\n",
    "            to_move -= 1\n",
    "            if to_move <= 0:\n",
    "                return move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_nt_kmer(index, pairs, seq): \n",
    "    \"\"\"convert sequence indexes into the corresponding nucleotides. \n",
    "    gaps are converted into '' \n",
    "    \"\"\"\n",
    "    seq_index = [pairs[x] for x in index]\n",
    "    nt_kmer = [seq[x] for x in seq_index]\n",
    "    return \"\".join(nt_kmer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_consecutive_seq(seq):\n",
    "    \"\"\"check if the sequence 'seq' consists of consecutive numbers\"\"\"\n",
    "    return len(set(list(map(lambda ix:ix[1]-ix[0], enumerate(seq))))) <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_correct_kmer(ev_index, pairs, read, ref):\n",
    "    \"\"\"check if a kmer corresponds completely wit the reference. \n",
    "    This is the case if: \n",
    "        * the read positions are consecutive (no indels)\n",
    "        * the ref positions are consecutive (no indels)\n",
    "        * the nucleotides are idential (no substitutions)\n",
    "    \"\"\"\n",
    "    assert(len(ev_index) == NMER), \"invalid event index\"\n",
    "    read_index = [pairs[0][x] for x in ev_index]\n",
    "    ref_index = [pairs[1][x] for x in ev_index]\n",
    "    \n",
    "    if None in read_index or not is_consecutive_seq(read_index): \n",
    "        \"\"\"indel in read\"\"\"\n",
    "        return False\n",
    "             \n",
    "    if None in ref_index or not is_consecutive_seq(ref_index): \n",
    "        \"\"\"indel in ref\"\"\"\n",
    "        return False\n",
    "             \n",
    "    read_seq = [read[x] for x in read_index]\n",
    "    ref_seq = [ref[x] for x in ref_index]\n",
    "    if read_seq == ref_seq:\n",
    "        \"\"\"full_match\"\"\"\n",
    "        return True\n",
    "    else: \n",
    "        \"\"\"substitution\"\"\"\n",
    "        return False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_events(pairs, file_obj):\n",
    "    event_list = file_obj[\"events\"].to_dict(\"records\")\n",
    "#     event_list = file_obj[\"events\"]\n",
    "    called_seq = file_obj[\"fastq\"].split(\"\\n\")[1]\n",
    "    i_seq = 0\n",
    "    correct = []\n",
    "    for ev in event_list:\n",
    "        ev[\"channel\"] = file_obj[\"channel\"]\n",
    "        ev_kmer = ev[\"kmer\"]\n",
    "        i_seq += gapmove(ev[\"move\"], pairs[0], i_seq)\n",
    "\n",
    "        try:\n",
    "            ev_index = event_indexes(pairs[0], i_seq)\n",
    "        except AlignmentEndException:\n",
    "            \"\"\"not the whole read is aligned\"\"\"\n",
    "            break\n",
    "        read_kmer = get_nt_kmer(ev_index, pairs[0], called_seq)       \n",
    "        assert(read_kmer == ev_kmer), (ev, read_kmer, ev_index)\n",
    "        if is_correct_kmer(ev_index, pairs, called_seq, ref):\n",
    "            correct.append(ev)\n",
    "    return correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6 156 ch156_file6_read\n",
      "1 1 157 ch157_file1_read\n",
      "2 19 135 ch135_file19_read\n",
      "3 5 204 ch204_file5_read\n",
      "4 0 135 ch135_file0_read\n",
      "5 10 206 ch206_file10_read\n",
      "6 14 209 ch209_file14_read\n",
      "7 3 211 ch211_file3_read\n",
      "8 27 215 ch215_file27_read\n",
      "9 15 215 ch215_file15_read\n",
      "10 9 215 ch215_file9_read\n",
      "11 38 132 ch132_file38_read\n",
      "12 8 141 ch141_file8_read\n",
      "13 0 157 ch157_file0_read\n",
      "14 1 201 ch201_file1_read\n",
      "15 1 203 ch203_file1_read\n",
      "16 28 211 ch211_file28_read\n",
      "17 11 223 ch223_file11_read\n",
      "18 5 227 ch227_file5_read\n",
      "19 18 142 ch142_file18_read\n",
      "20 35 132 ch132_file35_read\n",
      "21 20 211 ch211_file20_read\n",
      "22 26 132 ch132_file26_read\n",
      "23 11 156 ch156_file11_read\n",
      "24 11 133 ch133_file11_read\n",
      "25 2 203 ch203_file2_read\n",
      "26 10 132 ch132_file10_read\n",
      "27 12 211 ch211_file12_read\n",
      "28 27 212 ch212_file27_read\n",
      "29 23 135 ch135_file23_read\n",
      "30 17 132 ch132_file17_read\n",
      "31 12 141 ch141_file12_read\n",
      "32 20 206 ch206_file20_read\n",
      "33 3 142 ch142_file3_read\n",
      "34 36 132 ch132_file36_read\n",
      "35 17 211 ch211_file17_read\n",
      "36 44 132 ch132_file44_read\n",
      "37 6 223 ch223_file6_read\n",
      "38 2 133 ch133_file2_read\n",
      "39 3 149 ch149_file3_read\n",
      "40 15 141 ch141_file15_read\n",
      "41 4 204 ch204_file4_read\n",
      "42 4 223 ch223_file4_read\n",
      "43 26 211 ch211_file26_read\n",
      "44 25 135 ch135_file25_read\n",
      "45 23 132 ch132_file23_read\n",
      "46 7 206 ch206_file7_read\n",
      "47 4 215 ch215_file4_read\n",
      "48 15 156 ch156_file15_read\n",
      "49 35 211 ch211_file35_read\n",
      "50 21 206 ch206_file21_read\n"
     ]
    }
   ],
   "source": [
    "total_events = 0\n",
    "\n",
    "p = Pool(args[\"ncores\"])\n",
    "\n",
    "result = []\n",
    "try:\n",
    "    for i, read in enumerate(reads):\n",
    "        file_id, channel_id = get_file_and_channel(read.query_name)\n",
    "        print(i, file_id, channel_id, read.query_name)\n",
    "        pairs = [list(t) for t in zip(*read.get_aligned_pairs())]\n",
    "        file_obj = get_file(channel_id, file_id)\n",
    "        assert(pairs[0][0] == 0), \"alignment is not null-indexed.\"\n",
    "\n",
    "        ## map read to events\n",
    "        total_events += len(file_obj[\"events\"].index)\n",
    "    #     total_events += len(file_obj[\"events\"])\n",
    "\n",
    "\n",
    "        result.append(p.apply_async(process_events,\n",
    "                                         [pairs, file_obj]))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_events = list(chain.from_iterable([r.get() for r in result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66466"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "405113\n"
     ]
    }
   ],
   "source": [
    "print(total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16406780330426327\n"
     ]
    }
   ],
   "source": [
    "print(len(true_events)/total_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(true_events,\n",
    "            open(\"{0}_true_events.pickle\".format(args[\"out_basename\"]), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SSH fonsi ipython fonsi",
   "language": "",
   "name": "rik_ssh_fonsi_ipythonfonsi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
