{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import ghmm\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "import numpy as np\n",
    "from itertools import product as iterproduct, chain\n",
    "from pprint import pprint\n",
    "import pysam\n",
    "import os\n",
    "import pandas\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import editdistance\n",
    "import sys\n",
    "import random\n",
    "from multiprocessing import Pool\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_validation.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/alignment_lib.ipynb\"\n",
    "%run \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/analysis_lib.ipynb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NMERS = 3\n",
    "NSTATES = 4**NMERS\n",
    "MULTIVARIATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_events.template.pickle\",\n",
    "    \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_calling\",\n",
    "    \"ref\": \"/home/ibis/gregor.sturm/nanopore/david_eccles_bc_ideas/mouse_ref.fa\",\n",
    "    \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/david_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "    \"ncores\": 4\n",
    "}\n",
    "\n",
    "# args = {\n",
    "#     \"events\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_events.template.pickle\",\n",
    "#     \"out_basename\" : \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_calling\",\n",
    "#     \"ref\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_ref.fasta\",\n",
    "#     \"hmm_params\": \"/home/ibis/gregor.sturm/nanopore/own/notebooks/03_pipeline/lambda_hmm_params_{0}mer.pickle\".format(NMERS),\n",
    "#     \"ncores\": 62\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HMM_PARAMS = pickle.load(open(args[\"hmm_params\"], 'rb'))\n",
    "HMM_PARAMS = OrderedDict(HMM_PARAMS)\n",
    "ALL_KMERS = [\"\".join(x) for x in iterproduct(\"ACGT\", repeat=NMERS)]\n",
    "assert HMM_PARAMS.keys() == ALL_KMERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat1(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 1/4. if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)] else 0.\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat0(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (9/10.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/10.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_transmat2(nmers):\n",
    "    \"\"\"make a transition matrix assuming move=0 or move=1 or move=2\"\"\"\n",
    "    n_components = len(ALL_KMERS)\n",
    "    transmat = np.empty((n_components, n_components))\n",
    "    for j, from_kmer in enumerate(ALL_KMERS):\n",
    "        for i, to_kmer in enumerate(ALL_KMERS):\n",
    "            p = 0\n",
    "            if from_kmer[-(NMERS-2):] == to_kmer[:(NMERS-2)]:\n",
    "                \"\"\"move=2\"\"\"\n",
    "                p = (20/50.) * (1/16.)\n",
    "            elif from_kmer[-(NMERS-1):] == to_kmer[:(NMERS-1)]:\n",
    "                \"\"\"move=1\"\"\"\n",
    "                p = (29/50.) * (1/4.) \n",
    "            elif from_kmer == to_kmer:\n",
    "                \"\"\"move=0\"\"\"\n",
    "                p = (1/50.) * 1\n",
    "            transmat[j, i] = p          \n",
    "            \n",
    "    return transmat.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mk_transmat = mk_transmat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "F = ghmm.Float()  # emission domain of this model\n",
    "\n",
    "def mk_model_multivariate():\n",
    "    # example code for a continuous HMM with gaussian emissions\n",
    "\n",
    "    A = mk_transmat(NMERS)\n",
    "    B = [ [ \n",
    "            [float(df[['mean']].mean()), float(df[['stdv']].mean())], #mu1, mu2\n",
    "            [x for x in chain(*df[['mean', 'stdv']].cov().values.tolist())], #covariance matrix\n",
    "        ] for df in HMM_PARAMS.values()]   # parameters of emission distributions in pairs of (mu, sigma)\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.MultivariateGaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mk_model_simple(): \n",
    "    \"\"\" simple model, only taking the means into account. \"\"\"\n",
    "    A = mk_transmat(NMERS)\n",
    "    B = [ [float(df[['mean']].mean()), float(df[['stdv']].mean())] #mu1, stdv\n",
    "            for df in HMM_PARAMS.values()]   # parameters of emission distributions in pairs of (mu, sigma)\n",
    "    pi = [1/float(NSTATES)] * NSTATES   # initial probabilities per state\n",
    "\n",
    "    # generate model from parameters\n",
    "    model = ghmm.HMMFromMatrices(F,ghmm.GaussianDistribution(F), A, B, pi)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mk_model():\n",
    "    if MULTIVARIATE: \n",
    "        return mk_model_multivariate()\n",
    "    else: \n",
    "        return mk_model_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = mk_model()\n",
    "s = str(model)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def result_to_seq(result):\n",
    "    states = result[0]\n",
    "    kmers = [ALL_KMERS[x] for x in states]\n",
    "    seq = [kmer[NMERS/2] for kmer in kmers]\n",
    "    return \"\".join(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(mixed):\n",
    "    \"\"\"mixed is a set of tuples (event_mean, event_stdv)\"\"\"\n",
    "    if MULTIVARIATE: \n",
    "        emissions = [x for x in chain(*mixed)]    \n",
    "    else: \n",
    "        emissions = [x[0] for x in mixed]\n",
    "    seq = ghmm.EmissionSequence(F, emissions)\n",
    "    result = model.viterbi(seq)\n",
    "    return result_to_seq(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = model.sampleSingle(10)\n",
    "s = [x for x in s]\n",
    "seq = zip([s[i] for i in range(0, len(s), 2)], [s[i] for i in range(1, len(s), 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert os.path.isfile(args[\"events\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ref_file = args[\"ref\"]\n",
    "test = !cat {ref_file} | grep \">\"\n",
    "print(test)\n",
    "ref = !cat {ref_file} | grep -v \">\"\n",
    "ref = ref[0]\n",
    "print(ref[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_data = pickle.load(open(args[\"events\"], 'rb'))\n",
    "file_data = [f for f in file_data if f is not None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prepare_filemap(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_read(file_obj):    \n",
    "    events = [x[\"mean\"] for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    seq = ghmm.EmissionSequence(F, events)\n",
    "    model.baumWelch(seq)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def basecall_read(file_obj):\n",
    "    events = [(x[\"mean\"], x[\"stdv\"]) for x in file_obj[\"events\"].to_dict(\"records\")]\n",
    "    called_seq = predict(events)\n",
    "    return (file_obj[\"channel\"], file_obj[\"file_id\"], called_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\" train with baum-welch \"\"\"\n",
    "for i, file_obj in enumerate(file_data): \n",
    "    sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "    train_read(file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = Pool(args[\"ncores\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Prediction: \")\n",
    "results = []\n",
    "try:\n",
    "    for i, res in enumerate(p.imap_unordered(basecall_read, file_data), 1):\n",
    "        results.append(res)\n",
    "        sys.stdout.write('\\rdone {0:%}'.format(i/float(len(file_data))))\n",
    "    p.close()\n",
    "    p.join()\n",
    "except KeyboardInterrupt:\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "types = [\"metrichor\", \"called\", \"random\"]\n",
    "fasta_files = {t: \"{0}.{1}.fa\".format(args[\"out_basename\"], t) for t in types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## metrichor fasta\n",
    "with open(fasta_files[\"metrichor\"], 'w') as f: \n",
    "    for file_obj in file_data: \n",
    "        f.write(\">ch{0}_file{1}_metrichor\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "        f.write(file_obj[\"fastq\"].split(\"\\n\")[1] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## called fasta/random fasta\n",
    "with open(fasta_files[\"called\"], 'w') as f: \n",
    "    with open(fasta_files[\"random\"], 'w') as fr:\n",
    "        for channel, file_id, seq in results: \n",
    "            f.write(\">ch{0}_file{1}_called\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "            fr.write(\">ch{0}_file{1}_random\".format(file_obj[\"channel\"], file_obj[\"file_id\"])+ \"\\n\")\n",
    "            f.write(seq + \"\\n\")\n",
    "            fr.write(\"\".join([random.choice(\"ACGT\") for _ in range(len(seq))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for t in types: \n",
    "    sam_file = \"{0}.{1}.sam\".format(args[\"out_basename\"], t)\n",
    "    graphmap(ref_file, fasta_files[t], sam_file, args[\"ncores\"])\n",
    "    prepare_sam(\"{0}.{1}\".format(args[\"out_basename\"], t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stats = []\n",
    "for t in types: \n",
    "    samfile = pysam.AlignmentFile(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t))\n",
    "    sst = samstats(samfile, ref)\n",
    "    stats.append(pandas.DataFrame(sst.print_summary()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(types)\n",
    "side_by_side(*stats)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\t0\t1\t2\t3\n",
    "0\tmapped_reads/total_reads\t80\t80\t100.000000%\n",
    "1\tsignificant_reads/total_reads\t8\t80\t10.000000%\n",
    "2\tmapped_nts/total_nts\t346480\t442175\t78.358116%\n",
    "3\teditdistance/alignment_length\t218648\t367553\t59.487475%\n",
    "4\talignment_score/alignment_length\t-55710\t367553\t-15.156998%\n",
    "5\tSNPs/mapped_nts\t101880\t346480\t29.404295%\n",
    "6\tins/mapped_nts\t95618\t346480\t27.596975%\n",
    "7\tdel/mapped_nts\t21073\t346480\t6.082025%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for t in types: \n",
    "    consensus = mk_consensus(\"{0}.{1}.sorted.bam\".format(args[\"out_basename\"], t))\n",
    "    consensus = consensus.split(\"\\n\")[1].to_upper()\n",
    "    print(t, needle(ref, consensus))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IPython (Python 2)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
